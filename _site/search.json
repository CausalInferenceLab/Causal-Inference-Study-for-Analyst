[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PseudoLab Causal Inference Team",
    "section": "",
    "text": "Chapter 1. Motivation\n\n\n\n\n\n\n\nchapter1\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 1 소개\n\n\n\n\n\n\nOct 27, 2023\n\n\nJinsoo shin\n\n\n\n\n\n\n  \n\n\n\n\nChapter 0. Causal Inference 라이브러리 정리\n\n\n\n\n\n\n\npackages\n\n\nchapter0\n\n\n\n\n인과추론 라이브러리 소개\n\n\n\n\n\n\nOct 27, 2023\n\n\neverything\n\n\n\n\n\n\n  \n\n\n\n\nRandomised Controoled Trial\n\n\n\n\n\n\n\nA/B Test\n\n\nRCT\n\n\n\n\n스터디 소개\n\n\n\n\n\n\nOct 27, 2023\n\n\nJINSOO SHIN\n\n\n\n\n\n\n  \n\n\n\n\nIntro. Casual하게 Causality 이해하기 소개\n\n\n\n\n\n\n\nnews\n\n\n\n\n스터디 소개\n\n\n\n\n\n\nOct 27, 2023\n\n\nJINSOO SHIN\n\n\n\n\n\n\n  \n\n\n\n\nChapter 2. Potential Outcomes\n\n\n\n\n\n\n\nchapter2\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 2 소개\n\n\n\n\n\n\nOct 27, 2023\n\n\nJinsoo shin\n\n\n\n\n\n\n  \n\n\n\n\nChapter 4. Causal Models\n\n\n\n\n\n\n\nchapter4\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 4 소개\n\n\n\n\n\n\nOct 27, 2023\n\n\nseongsoo kim & hojae jeong\n\n\n\n\n\n\n  \n\n\n\n\nChapter 3. Graphical Models\n\n\n\n\n\n\n\nchapter3\n\n\n\n\nIntroduction to Causal Inference 강의 chapter 3 소개\n\n\n\n\n\n\nOct 27, 2023\n\n\nseongchul hong\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "PseudoLab Causal Inference Team",
    "section": "",
    "text": "about\n안녕하세요. 가짜연구소 Causal Inference 팀입니다.\n데이터를 통한 문제해결력을 높이기 위해 Causal Inference를 함께 학습하고 있어요✌️\n한국어 자료가 많지 않은 인과추론을 많은 분들이 쉽게 접하실 수 있도록 기여하고자 합니다!\n\n\n\n인과추론팀 빌더\n\n\n\n이름\n소속\n소개\n\n\n\n\n신진수\n크래프톤 Data Analyst\nGithub / LinkedIn\n\n\n\n\n\nStudy : 인과추론 with Entertainment\n\n\n\n이름\n소속\n소개\n\n\n\n\n김소희\n티빙 Data Analyst\nLinkedIn\n\n\n김지연\n엔씨소프트 Data Analyst\n\n\n\n박시온\n넥슨코리아 Data Analyst\n\n\n\n박병수\n넥슨코리아 Data Analyst\n\n\n\n박이삭\n넥슨코리아 Data Analyst\n\n\n\n유정현\n넥슨코리아 Data Analyst\n\n\n\n임종언\n넥슨코리아 Data Analyst\n\n\n\n조슬지\n넷마블 Data Analyst\n\n\n\n\n\n\nStudy : 인과추론 라이브러리\n\n\nResearch : 인과추론 논문쓰기\n\n\nTech Support\n김상돈 | | |\n최은희 | 넥슨코리아 Data Analyst | |\n홍성철 | 엔씨소프트 Data Analyst | |"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Intro. Casual하게 Causality 이해하기 소개",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀입니다.\n지난 3개월 간 가짜연구소에서 “Casual하게 Causality 이해하기” 스터디가 진행되었습니다.\n해당 스터디를 통해 저희가 달성하고자 하는 목표는 크게 3가지입니다.\n\n◦ Causal Inference에 대한 기본적인 개념 학습\n◦ 문제 or ML 모델에 대한 원인 분석 능력 키우기\n◦ 공부한 내용을 정리해, Causal Inference 에 대한 한국어 자료 만들어보기\n\n\n인과추론을 공부하러 오신 분들이 저희가 작성한 블로그를 통해,\n한국어 자료가 많지 않은 인과추론에 더 쉽게 다가가셨으면 좋겠습니다!\n\n\n“Casual하게 Causality 이해하기” 스터디는 Brady Neal의 Introduction to Causal Inference 강의를 바탕으로 진행되었습니다.\n블로그 글 이전에 전체 챕터에 대한 노션 페이지 정리 자료를 보고 싶으신 분들은 가짜연구소 Causal Inference 아카이브를 참고해주시면 감사하겠습니다!"
  },
  {
    "objectID": "about.html#스터디-자료-소개",
    "href": "about.html#스터디-자료-소개",
    "title": "게임/엔터 산업의 분석가를 위한 인과추론 스터디 : Causal-Inference-Study-for-Analyst",
    "section": "",
    "text": "안녕하세요. 가짜연구소 Causal Inference 팀 신진수 입니다.\n 가짜연구소 인과추론팀은 데이터를 통한 문제해결력을 높이기 위해 Causal Inference를 함께 학습하고 있어요✌️ 한국어 자료가 많지 않은 인과추론을 많은 분들이 쉽게 접하실 수 있도록 기여하고자 합니다! 가짜연 디스코드 커뮤니티 에 오셔서 인과추론에 대해 많은 이야기를 같이 나눠봐요!\n 해당 자료는 가짜연구소 인과추론팀에 속한 게임/엔터 분야의 현업 데이터 분석가분들이 아래 자료를 바탕으로 요약 및 현업에서의 고민과 생각을 담아 정리했습니다.\n\n\n고수들의 계량경제학\nCausal Inference for the brave and true / [한국어 번역자료]\n인과추론의 데이터 과학\n\n\n혹시 잘못된 내용이나 오타가 발견되면, 해당 Github 저장소의 이슈 페이지를 방문해주세요. 또한, 관련 질문은 빌더인 신진수에게 문의 부탁드립니다."
  },
  {
    "objectID": "about.html#인과추론-개념정리-스터디-일정",
    "href": "about.html#인과추론-개념정리-스터디-일정",
    "title": "게임/엔터 산업의 분석가를 위한 인과추론 스터디 : Causal-Inference-Study-for-Analyst",
    "section": "",
    "text": "해당 스터디 Summary 11개 정도의 챕터로 구성 예정입니다.\n\n\n\n순서\n완료여부\nChapter\n발표일\n작성자 (소속)\n\n\n\n\n1\n☑️\n1. Randomised Controlled Trial\n2023-07-09\n신진수 (크래프톤)\n\n\n2\n\n2. Regression\n2023-07-23\n박시온 (넥슨코리아)"
  },
  {
    "objectID": "posts/2023-10-18-intro/index.html",
    "href": "posts/2023-10-18-intro/index.html",
    "title": "Intro. Casual하게 Causality 이해하기 소개",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀입니다.\n지난 3개월 간 가짜연구소에서 “Casual하게 Causality 이해하기” 스터디가 진행되었습니다.\n해당 스터디를 통해 저희가 달성하고자 하는 목표는 크게 3가지입니다.\n\n◦ Causal Inference에 대한 기본적인 개념 학습\n◦ 문제 or ML 모델에 대한 원인 분석 능력 키우기\n◦ 공부한 내용을 정리해, Causal Inference 에 대한 한국어 자료 만들어보기\n\n\n인과추론을 공부하러 오신 분들이 저희가 작성한 블로그를 통해,\n한국어 자료가 많지 않은 인과추론에 더 쉽게 다가가셨으면 좋겠습니다!\n\n\n“Casual하게 Causality 이해하기” 스터디는 Brady Neal의 Introduction to Causal Inference 강의를 바탕으로 진행되었습니다.\n블로그 글 이전에 전체 챕터에 대한 노션 페이지 정리 자료를 보고 싶으신 분들은 가짜연구소 Causal Inference 아카이브를 참고해주시면 감사하겠습니다!\n\n\n\nCitationBibTeX citation:@online{shin2023,\n  author = {SHIN, JINSOO},\n  title = {Intro. {Casual하게} {Causality} {이해하기} {소개}},\n  date = {2023-10-27},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSHIN, JINSOO. 2023. “Intro. Casual하게 Causality 이해하기\n소개.” October 27, 2023."
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "👉 해당 포스트는 아래 인과추론 자료를 바탕으로 정리했습니다. - 고수들의 계량경제학 1장 무작위 시행 - Causal Inference for the brave and true Chapter 2. Randomised Experiments / 한국어 번역 자료 - 인과추론의 데이터 과학\n\n\n\n\n\n배운내용을 어떻게 현업에서 활용할지 & 사례를 바탕으로 느낀점에 중점\n단순 책 내용을 요약하는 건 앞으로 실제 업무 활용 시, 도움이 안될 수 있으므로 본인만의 방식으로 재구조화\n\n\n\n\n목적 : 해당 챕터를 배우는 이유는 무엇일까?\n\n실험 디자인 시, 이상적이지만, Treatment 인과효과 추정에 가장 효과적인 방법\n\n\n\n\n내용 : 이번 챕터에서 어떤 메세지를 전달하려고 하는가?\n\n모집단을 가지고 실험을 하는 것은 현실적으로 어려움. 따라서, 모집단과 유사한 그룹 샘플 데이터를 바탕으로 Random Assignment 하는 것이 핵심\nRandomised Experiments 상황에서, Association = Causation\n\n결국, 유저를 랜덤하게 나눌 수 있는 환경이면, 복잡한 실험디자인 or 통계 모형을 사용하지 않아도 Causal Effect 추정이 가능\n\nRCT 이후에 배울 내용 IV, DID, RDD, Matching, Synthetic Control이 왜 필요한지 내포하는 챕터\n\n참고로, 위의 방법론은 실험 디자인을 잘 활용해서, 두 그룹을 비교 가능하게 만들어주는 방법\n\n\n\n\n\n느낀점 : 배운 내용을 어떻게 현업에서 적용해볼 수 있는가? 왜 적용이 어려울까?\n\n직관과 실험 : 어떻게 보면 당연한, 검증 작업에 직관보다는 실험이 필요하지만, 아래 상황들로 인해 여의치 않음\n조직 문화 : OCE (Online Controlled Experiment) 플랫폼을 구축하는 것은 혼자 할 수 없으며, 조직 차원에서 실험의 중요성을 이해하고 있어야 함\n\nNAVER Search A/B Test 플랫폼 [Blog Link] / [Video]\n오늘의 집 A/B 실험 플랫폼 구축기 [Link]\n\n리소스 : 이해 부서와 실험 설계를 같이하고 분석을 진행하는 것은 시간과 비용 소모가 큰 작업. 따라서, 실험 설계단계에서 각 조직의 성과 지표 Align이 되었는지 확인 필요\n유저 경험 : 동일 빌드에서 어떤 유저에게만 프로모션을 하는 것은 라이브 서비스 측면에서 안좋을 수 있음\n분석가의 고충\n\n기획/개발 단계에서 검증해야할 지표가 제대로 협의/논의되지 않음\nData Generating Process : 로그는 잘 남고 있을까?\n실험을 진행할 유저군이 랜덤하게 나뉘어지지 않음 (Selection Bias)\nConfounding Factor 제대로 통제하지 못하는 케이스가 존재 (기간 / 그룹특성)\n\n\n\n\n\n어려운점 : 어떤 부분이 해당 챕터를 다룰 때 어렵고 생소했나?\n\n도메인 지식 : 미국의 의료보험 체계 및 사회적인 배경을 잘 몰라서, 내용을 이해하는데 까다로웠음\n가설검정과 인과추론 : 어떤 부분에서 관련이 있는지 생각하는데, 시간을 많이 쏟음\n\n\n\n\n\n\n\n\n\n💡Causal Inference is concerned with a very specific kind of prediction problem\n\nPredicting the results of an action, manipulation, or Intervention - “Making Things Happen” (2003, Woodward)\n\n\n\n\n\n인과추론 (Causal Inference)이란 무엇일까?\n\n문제에 대한 원인을 찾고 해당 원인에 대한 효과를 추론하는 것\n즉, Treatment를 주었을 때, 이에 따른 Outcome이 어떻게 바뀌는지를 추정\n\n이벤트(Treatment)를 진행하면, 유저의 잔존율(Outcome)이 높아질까?\n\n\n\n\n\n그러면 ML과 무엇이 다른가? &lt; Causal Inference vs Machine Learning &gt;\n\nCausal Inference : Potential outcomes까지 고려\nMachine Learning : Observed outcomes만을 고려\n\n\n\n\n상관관계는 인과관계를 의미하지 않음. Why? Confounding Factors\n\n\n\nimg\n\n\n\n✅ Standard Approach & Causal Approach\n\n기본 접근 : \\(X\\)의 변화가 \\(Y\\)의 변화와 어떻게 연관되어 있는지 정량화하는데 관심\n\n\\(Y = β_0 + β_1X+ ε\\) → \\(E(Y|X=x+1) - E(Y|X=x)\\)\nRegression (Chapter 2)에서 다룰 기본적인 접근\n\n인과추론 접근 : \\(X\\) (원인)의 변화가 \\(Y\\)의 변화를 유발하는지를 확인하는데 관심\n\n해당 접근은 Y가 변하는 이유(원인)에 대한 질문에 답을 할 수 있음\n만약 \\(X\\)와 \\(Y\\)가 인과적으로 관계가 있다면, \\(Y\\)의 변화는 \\(X\\)의 변화로 설명 가능\n\n\n\n\n\n\n\n\n\n▶️ 건강보험이 건강에 미치는 인과효과 추정 &lt;고수들의 계량경제학 Chapter 1. 무작위 시행&gt;\n\n\n\n\n\n목적 : 보험 가입이 실험 대상에 미치는 영향을 2가지 관점에서 파악 → 실험 규모와 비용을 고려 시, 여러 가지의 목표 지표 설정이 가능하도록 설계 할 수 있음\n\n가설 1 : 보험 의료 가격이 감소하면, 실제로 의료 서비스를 더 사용할 것이다. → Yes\n가설 2 : 보험 가입을 통해, 건강 증진의 인과적 효과가 있을 것이다. → No\n\n\n\n\n\n\n\n배경 : 국가 정책을 위해, 영향을 받는 모든 국민을 대상으로 테스트하면 아래와 같은 문제 발생 할 수 있음\n\n국가적으로 너무나 큰 리소스가 들어가며 통제 하기 쉽지 않음\n또한, Random Assignment 과정에서 윤리적인 부분이 이슈가 될 수 있음\n\n\n\n\n목적 : 모집단 (Population)을 잘 반영하는 실험 유저군 (Sampling Group)을 적절히 샘플링\n\nSampling Bias 최소화\nApple to Apple (Random Assignment)\n\n\n\n\n실험 그룹 설계 : 올바른 실험설계를 통해, 목적에 맞는 인과효과를 추정하기 위함\n\n테스트 가능한 가설 설계 및 목표 지표 설계\n\nPrimary Index &lt;궁극적인 목표가 되는 지표&gt; : 지출한 의료비 / 건강 지표\nSecondary Index &lt;실험과 직접적 연관이 되는 지표&gt; : 부담 보험료\nGuardrail Index &lt;실험 과정에 부정적 영향을 받을 수 있는 지표&gt; : 건강 지표 푸시를 했는데 이탈하는 유저가 발생한 Nexon 사례\n\n\n\n\n실험군/대조군 설정 : 보험의 보장 수준 (가입자 부담 보험료 수준)에 따라 5개 상품으로 구분\n\nControl Group : 무보험 상태에 가까운 보험 수준을 가진 상품 (재난적 플랜)\nTreatment Group : 그 외 보험 보장이 되는 상품군 (4가지)\n\n\n\n\n방법 : 보험 미가입자를 대상으로 5개의 보험 상품에 Random Assignment\n\n\n\n그룹 검증 : 과연 랜덤하게 나눈 실험군과 대조군이 서로 비교 가능한가 (Ceteris Paribus)\n\n실험 대상 (유저/국민)을 대표할 수 있는 비교 변수 설정 (Ex. 나이/연령/과금 수준 등)\n통계적으로 유의미한 차이가 발생했는지 확인 → 상황에 따라 A/A 테스트 진행을 하기도 함\n표본의 수가 충분한지 (Law of Large Numbers 나온 배경) & 동일한 수준으로 제대로 나뉘었는지 체크 필요\n\n→ 해당 실험에서 그룹간 차이는 무시해도 되는 것으로 보여짐\n\n\n\n\n\n\n실험 진행 시 체크 사항\n\n지표 모니터링 : 실험이 진행되는 동안, 실험 대상/유저가 받게될 경험에 부정적인 요소가 있는지 & 실험에 영향을 주는 외부 요인이 있는지 모니터링\n로그 확인 : 실험 분석에 진행될 로그가 잘 쌓이고 있는지 확인\n\n\n\n\n실험 분석 : 리포트 및 실험 Dashboard 제공\n\n해당 실험을 통해, 유저의 경험을 어떤 측면에서 개선했는지 사전 설계 지표 및 실험 그룹을 바탕으로 성과 분석\n\n\n\n\n\n\n\n목적 :\n\n실험을 바탕으로 조직 내 의사결정에 활용 → 보험 가입이 건강 증진에 도움이 될까? No\n이번 실험에서 얻은 Insight와 보완점을 통해, 이후 실험 과정 개선\n(반복 실험이 가능하다면) 이를 바탕으로, 실험을 개선 결과의 신뢰성을 높이기 위해 노력\n\n\n\n\n건강 보험 실험 Feedback\n\n실험 설계의 문제 : 건강보험이라는 국가적 실험에서 완벽한 Random Assignment가 된 것이 맞을까?\n\nSampling Bias : 모집단 (실제로 보험에 가입하지 않은 사람들)과 샘플 그룹 (재난적 플랜에 가입된 Control Group) 간의 차이가 존재\nUnobserved Confounders : 관측된 인구통계 정보를 바탕으로 설계를 했을 때, 약간의 Sampling Bias 존재. 그렇다면, 관측되지 않은 변수에서는 해당 부분이 더 크게 나타날 수 있지 않을까?\nCensoring Issue : 실험 중도 이탈자 / 실험군이지만, 영향을 받지 않은 유저는 어떻게 처리를 했는가? 제외했다면 Selection Bias가 아닌가?\n\n\n\n\n결과의 유효성 : 보험 증진으로 건강 개선을 할 수 없었던 것이 맞을까?\n\n목표 지표 : 건강 지표는 과연 객관적으로 정량화가 가능한 부분인가?\n실험 개선 : 보험 가입에 의한 효과가 없다면 이후의 실험 개선은? 오리건의 건강 보험 실험\n\n\n\n\n\n\n\n\n\n\n목적 : 결국, 인과추론의 근본적인 문제를 이해하고 효과적으로 해결해나가기 위함\n\nTreatment : 접속 이벤트 참여 여부\n\n실험군 (Treatment Group) : 이벤트 참여에 배정된 유저군\n대조군 (Control Group) : 이벤트 참여에 배정되지 않은 유저군\n\nOutcome : 유저 잔존율\n\n비교 그룹간 유의미한 차이 (ATE, Average Treatment Effect)가 있는지 확인하는 지표\n\n\n\n\n\n문제 : Counterfactuals (Counter to fact, 일어나지 않은 상황을 가정)\n\n실험 진행 시, 유저는 참여/미참여 중 한 개의 상태로만 존재할 수 있음\n따라서, 실험 당시 미참여 유저가 그렇지 참여한 상황(실제로 일어나지 않음)을 가정\n하지만, 우리는 타임머신이 없기 때문에 동일한 유저에 대해서 2가지 사항을 관측 불가\n→ 인과추론의 근본적인 문제 \n\n\n\nimg\n\n\n\n\n\n\n\n\n하나의 실험 대상에 대해 Treatment에 대한 Potential Outcomes 모두 관찰 불가\n\nSelection Bias 발생하는 이유?\n\n인과추론 근본적인 문제 : Control Group ≠ Counterfactuals\n특성이 다른 다른 대상과 비교 시 Selection Bias가 발생 : &lt;쿠즈다르와 마리아 사례&gt;\n\n결국, 이 문제가 해결이 되어야 Treatment에 따른 인과적인 효과 파악이 가능\n\n\n\n\nIndividual Treatment Effect (ITE) : 개별 유저 i 에 대해 Treatment 처지 효과\n\n유저 i 에게는 2가지 Potential Outcomes이 존재\n\n\\(T = 1\\) : 이벤트 참여 / \\(T = 0\\) : 이벤트 미참여\n2가지 Potential Outcomes 중에서 하나만 존재할 수 있음\n유저 i 에 대한 개별 인과효과 (ITE)\n$ ITE = Y_{0i} - Y_{1i} $\n\n\nAverage Treatment Effect (ATE) : 유저 그룹에 대한 Treatment 처지 효과\n\n유저 개인화 관점에서는 ITE가 이상적이고 중요하지만, 대부분은 유저 그룹단위의 실험이 일반적이며 개개인에 대해 ITE를 파악할 수 없는 경우가 존재\n따라서, 유저 개인의 인과효과를 평균을 내어 집단 레벨에서 설명\n만약, 제대로 된 실험 설계를 하지 않고 ATE를 계산한다면? 아래와 같은 Selection Bias가 생김 &lt;Causal Inference for the brave and true Chapter1. 수식 참조&gt;\n\n$ E[Y|T=1] - E[Y|T=0] = E[Y_1|T=1] - E[Y_0|T=0] + E[Y_0|T=1] - E[Y_0|T=1] $\n$ E[Y|T=1] - E[Y|T=0] = {ATT} + $\n\n\n\n\n\n인과추론의 근본적인 문제를 바라보는 3가지 관점\n\nPotential Outcomes : 물음표 채우기\nStructural Causal Models : DAG\nRegression → 다음 챕터가 Regression인 이유!\n\n오차항 가정(Gaussian Assumption)과 내생성 (Endogenity) → 도구변수 참조\n\n\n\n\n\nSelection Bias 해결하기 위해 이번 챕터에서는 Random Assignment 도입\n\n즉, 실험 대상를 동전던지기로 나눠서 Treatment 여부를 결정\n\n\n\n\nRandom Assignment이 가장 좋은 방법이지만, Research Design 필요성 존재\n\n목적 :\n\n하지만, 항상 주어진 상황에서 RCT를 활용할 수 없는 경우가 많음\n위와 같은 경우, Counterfactual과 최대한 비슷한 Control Group를 실험 디자인을 통해 찾아나가야 함 ↔︎ Selection Bias 줄이기\n\n\n\n\n실험 디자인 방법론 (To be continued)\n\nInstrumental Varibles (2SLS / Regression, Chapter 3)\nRDD (Regression Discontinuity Design, Chapter 4)\nDID (Difference In Difference, Chapter 5)\nSynthetic Control\n\n\n\n\n\n\n\nLLN (Law of Large Numbers) 나오게 된 배경\n\n결국 모집단을 잘 대표하는 표본(Sample)을 선정하기 위해, 충분한 수의 표본이 필요\n궁극적으로, 실험군과 대조군은 동일한 모집단에서 생성 → 그룹간에 비교 가능한 특성을 가져야함 → 해당 조건 달성을 위해서는 충분한 표본이 필요\n과연 Sample Size는 어떤 수준이 적절할까?\n\nStatistical Power(검정력)과 Sample Size\nProduct Active User 규모를 고려\n\n\n\n\n\nHypothesis Testing\n\n목적 : 모집단 (Population Data)의 특성에 대해 설계한 통계적 가설 (\\(H_0\\) / \\(H_1\\))을 모집단의 추출한 샘플 데이터 (Sample Data)를 이용해 검증하는 과정\n인과추론과 가설 검정 : 결국, 인과적인 효과를 추정하기 위해 모집단의 데이터를 활용하는 것보다는 샘플 데이터를 이용해, 개입 (Intervention)에 따른 효과가 있는지 검증\n\n그래서, 후반부에 가설 검정 T-test ↔︎ Two Sample T-test (↔︎ Hausman Test)이 나오게된 것 같음\n\n\n\n\n\n\n\n\nA/B 테스트를 할 수 있는 오픈 소스 및 자료\n\n자체 OCE (Online Controlled Experiment) 플랫폼이 있다면 최적의 환경\n실제로 3rd Party 툴 (Amplitude / Braze / Firebase 등)을 통해서 A/B Test를 해볼 수 있음\nGrowthBook과 같이 잘 알려진 오픈 소스를 통해, 현업에 적용이 가능\n오픈 소스 정리자료 링크 : https://posthog.com/blog/best-open-source-ab-testing-tools\n\n\n\n\n실험 플랫폼\n\n직관이 아닌 실험으로의 의사결정은 조직에서 매우 중요한 과제\n참고 도서 : 실리콘밸리의 실험\n\n\n\n\n\n\n(종언) 실험에 사용할 샘플 사이즈는 어떻게 가져가는게 좋을까요?\n\n(이삭) : 통계학적인 방법으로는 Statistical Power과 샘플 사이즈가 양의 상관관계가 있어, 검정력을 기준으로 샘플 사이즈가 적절한지 판단하는 것 같습니다,\n(소희) : 적정 샘플 사이즈를 계산해주는 사이트를 사용해봤어요.\n(진수) : 오히려 너무 적은 극단적인 케이스는 Bias가 많고 일반적으로 정상적인 범주에서 벗어났다고 생각해, 실험 대상으로는 제외했던 기억이 있습니다. 원론적인 답변이지만 항상 Product의 Active User 수를 고려해야 할 것 같습니다.\n\n\n\n\n(이삭) 의료 보험 가입으로 건강 증진의 효과를 얻지 못했는데, 미국의 사례여서 그런걸까요?\n\n(정현) : 의료 보험 체계가 다르지만 한국도 비슷하지 않을까 싶습니다. 그런데 실험을 해보지 않아서 직관적인 판단에 주의해야할 것 같아요.\n\n\n\n\n\n\n고수들의 계량경제학 Chapter 1. 무작위 시행 &lt;Joshua D. Angrist , Jorn-Steffen Pischke 저&gt;\nCausal Inference for the brave and true Chapter 1. Introduction to Causality \nKorea Summer Workshop on Causal Inference 2022\nIntroduction to Causal Inference\n유 퀴즈 온 더 블럭 - 구준엽편"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#chapter-summary",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#chapter-summary",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "배운내용을 어떻게 현업에서 활용할지 & 사례를 바탕으로 느낀점에 중점\n단순 책 내용을 요약하는 건 앞으로 실제 업무 활용 시, 도움이 안될 수 있으므로 본인만의 방식으로 재구조화\n\n\n\n\n목적 : 해당 챕터를 배우는 이유는 무엇일까?\n\n실험 디자인 시, 이상적이지만, Treatment 인과효과 추정에 가장 효과적인 방법\n\n\n\n\n내용 : 이번 챕터에서 어떤 메세지를 전달하려고 하는가?\n\n모집단을 가지고 실험을 하는 것은 현실적으로 어려움. 따라서, 모집단과 유사한 그룹 샘플 데이터를 바탕으로 Random Assignment 하는 것이 핵심\nRandomised Experiments 상황에서, Association = Causation\n\n결국, 유저를 랜덤하게 나눌 수 있는 환경이면, 복잡한 실험디자인 or 통계 모형을 사용하지 않아도 Causal Effect 추정이 가능\n\nRCT 이후에 배울 내용 IV, DID, RDD, Matching, Synthetic Control이 왜 필요한지 내포하는 챕터\n\n참고로, 위의 방법론은 실험 디자인을 잘 활용해서, 두 그룹을 비교 가능하게 만들어주는 방법\n\n\n\n\n\n느낀점 : 배운 내용을 어떻게 현업에서 적용해볼 수 있는가? 왜 적용이 어려울까?\n\n직관과 실험 : 어떻게 보면 당연한, 검증 작업에 직관보다는 실험이 필요하지만, 아래 상황들로 인해 여의치 않음\n조직 문화 : OCE (Online Controlled Experiment) 플랫폼을 구축하는 것은 혼자 할 수 없으며, 조직 차원에서 실험의 중요성을 이해하고 있어야 함\n\nNAVER Search A/B Test 플랫폼 [Blog Link] / [Video]\n오늘의 집 A/B 실험 플랫폼 구축기 [Link]\n\n리소스 : 이해 부서와 실험 설계를 같이하고 분석을 진행하는 것은 시간과 비용 소모가 큰 작업. 따라서, 실험 설계단계에서 각 조직의 성과 지표 Align이 되었는지 확인 필요\n유저 경험 : 동일 빌드에서 어떤 유저에게만 프로모션을 하는 것은 라이브 서비스 측면에서 안좋을 수 있음\n분석가의 고충\n\n기획/개발 단계에서 검증해야할 지표가 제대로 협의/논의되지 않음\nData Generating Process : 로그는 잘 남고 있을까?\n실험을 진행할 유저군이 랜덤하게 나뉘어지지 않음 (Selection Bias)\nConfounding Factor 제대로 통제하지 못하는 케이스가 존재 (기간 / 그룹특성)\n\n\n\n\n\n어려운점 : 어떤 부분이 해당 챕터를 다룰 때 어렵고 생소했나?\n\n도메인 지식 : 미국의 의료보험 체계 및 사회적인 배경을 잘 몰라서, 내용을 이해하는데 까다로웠음\n가설검정과 인과추론 : 어떤 부분에서 관련이 있는지 생각하는데, 시간을 많이 쏟음"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#introduction-to-causal-inference",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#introduction-to-causal-inference",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "💡Causal Inference is concerned with a very specific kind of prediction problem\n\nPredicting the results of an action, manipulation, or Intervention - “Making Things Happen” (2003, Woodward)\n\n\n\n\n\n인과추론 (Causal Inference)이란 무엇일까?\n\n문제에 대한 원인을 찾고 해당 원인에 대한 효과를 추론하는 것\n즉, Treatment를 주었을 때, 이에 따른 Outcome이 어떻게 바뀌는지를 추정\n\n이벤트(Treatment)를 진행하면, 유저의 잔존율(Outcome)이 높아질까?\n\n\n\n\n\n그러면 ML과 무엇이 다른가? &lt; Causal Inference vs Machine Learning &gt;\n\nCausal Inference : Potential outcomes까지 고려\nMachine Learning : Observed outcomes만을 고려\n\n\n\n\n상관관계는 인과관계를 의미하지 않음. Why? Confounding Factors\n\n\n\nimg\n\n\n\n✅ Standard Approach & Causal Approach\n\n기본 접근 : \\(X\\)의 변화가 \\(Y\\)의 변화와 어떻게 연관되어 있는지 정량화하는데 관심\n\n\\(Y = β_0 + β_1X+ ε\\) → \\(E(Y|X=x+1) - E(Y|X=x)\\)\nRegression (Chapter 2)에서 다룰 기본적인 접근\n\n인과추론 접근 : \\(X\\) (원인)의 변화가 \\(Y\\)의 변화를 유발하는지를 확인하는데 관심\n\n해당 접근은 Y가 변하는 이유(원인)에 대한 질문에 답을 할 수 있음\n만약 \\(X\\)와 \\(Y\\)가 인과적으로 관계가 있다면, \\(Y\\)의 변화는 \\(X\\)의 변화로 설명 가능"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#experiment-key-takeaway",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#experiment-key-takeaway",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "▶️ 건강보험이 건강에 미치는 인과효과 추정 &lt;고수들의 계량경제학 Chapter 1. 무작위 시행&gt;\n\n\n\n\n\n목적 : 보험 가입이 실험 대상에 미치는 영향을 2가지 관점에서 파악 → 실험 규모와 비용을 고려 시, 여러 가지의 목표 지표 설정이 가능하도록 설계 할 수 있음\n\n가설 1 : 보험 의료 가격이 감소하면, 실제로 의료 서비스를 더 사용할 것이다. → Yes\n가설 2 : 보험 가입을 통해, 건강 증진의 인과적 효과가 있을 것이다. → No\n\n\n\n\n\n\n\n배경 : 국가 정책을 위해, 영향을 받는 모든 국민을 대상으로 테스트하면 아래와 같은 문제 발생 할 수 있음\n\n국가적으로 너무나 큰 리소스가 들어가며 통제 하기 쉽지 않음\n또한, Random Assignment 과정에서 윤리적인 부분이 이슈가 될 수 있음\n\n\n\n\n목적 : 모집단 (Population)을 잘 반영하는 실험 유저군 (Sampling Group)을 적절히 샘플링\n\nSampling Bias 최소화\nApple to Apple (Random Assignment)\n\n\n\n\n실험 그룹 설계 : 올바른 실험설계를 통해, 목적에 맞는 인과효과를 추정하기 위함\n\n테스트 가능한 가설 설계 및 목표 지표 설계\n\nPrimary Index &lt;궁극적인 목표가 되는 지표&gt; : 지출한 의료비 / 건강 지표\nSecondary Index &lt;실험과 직접적 연관이 되는 지표&gt; : 부담 보험료\nGuardrail Index &lt;실험 과정에 부정적 영향을 받을 수 있는 지표&gt; : 건강 지표 푸시를 했는데 이탈하는 유저가 발생한 Nexon 사례\n\n\n\n\n실험군/대조군 설정 : 보험의 보장 수준 (가입자 부담 보험료 수준)에 따라 5개 상품으로 구분\n\nControl Group : 무보험 상태에 가까운 보험 수준을 가진 상품 (재난적 플랜)\nTreatment Group : 그 외 보험 보장이 되는 상품군 (4가지)\n\n\n\n\n방법 : 보험 미가입자를 대상으로 5개의 보험 상품에 Random Assignment\n\n\n\n그룹 검증 : 과연 랜덤하게 나눈 실험군과 대조군이 서로 비교 가능한가 (Ceteris Paribus)\n\n실험 대상 (유저/국민)을 대표할 수 있는 비교 변수 설정 (Ex. 나이/연령/과금 수준 등)\n통계적으로 유의미한 차이가 발생했는지 확인 → 상황에 따라 A/A 테스트 진행을 하기도 함\n표본의 수가 충분한지 (Law of Large Numbers 나온 배경) & 동일한 수준으로 제대로 나뉘었는지 체크 필요\n\n→ 해당 실험에서 그룹간 차이는 무시해도 되는 것으로 보여짐\n\n\n\n\n\n\n실험 진행 시 체크 사항\n\n지표 모니터링 : 실험이 진행되는 동안, 실험 대상/유저가 받게될 경험에 부정적인 요소가 있는지 & 실험에 영향을 주는 외부 요인이 있는지 모니터링\n로그 확인 : 실험 분석에 진행될 로그가 잘 쌓이고 있는지 확인\n\n\n\n\n실험 분석 : 리포트 및 실험 Dashboard 제공\n\n해당 실험을 통해, 유저의 경험을 어떤 측면에서 개선했는지 사전 설계 지표 및 실험 그룹을 바탕으로 성과 분석\n\n\n\n\n\n\n\n목적 :\n\n실험을 바탕으로 조직 내 의사결정에 활용 → 보험 가입이 건강 증진에 도움이 될까? No\n이번 실험에서 얻은 Insight와 보완점을 통해, 이후 실험 과정 개선\n(반복 실험이 가능하다면) 이를 바탕으로, 실험을 개선 결과의 신뢰성을 높이기 위해 노력\n\n\n\n\n건강 보험 실험 Feedback\n\n실험 설계의 문제 : 건강보험이라는 국가적 실험에서 완벽한 Random Assignment가 된 것이 맞을까?\n\nSampling Bias : 모집단 (실제로 보험에 가입하지 않은 사람들)과 샘플 그룹 (재난적 플랜에 가입된 Control Group) 간의 차이가 존재\nUnobserved Confounders : 관측된 인구통계 정보를 바탕으로 설계를 했을 때, 약간의 Sampling Bias 존재. 그렇다면, 관측되지 않은 변수에서는 해당 부분이 더 크게 나타날 수 있지 않을까?\nCensoring Issue : 실험 중도 이탈자 / 실험군이지만, 영향을 받지 않은 유저는 어떻게 처리를 했는가? 제외했다면 Selection Bias가 아닌가?\n\n\n\n\n결과의 유효성 : 보험 증진으로 건강 개선을 할 수 없었던 것이 맞을까?\n\n목표 지표 : 건강 지표는 과연 객관적으로 정량화가 가능한 부분인가?\n실험 개선 : 보험 가입에 의한 효과가 없다면 이후의 실험 개선은? 오리건의 건강 보험 실험"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#theoretical-backgroud",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#theoretical-backgroud",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "목적 : 결국, 인과추론의 근본적인 문제를 이해하고 효과적으로 해결해나가기 위함\n\nTreatment : 접속 이벤트 참여 여부\n\n실험군 (Treatment Group) : 이벤트 참여에 배정된 유저군\n대조군 (Control Group) : 이벤트 참여에 배정되지 않은 유저군\n\nOutcome : 유저 잔존율\n\n비교 그룹간 유의미한 차이 (ATE, Average Treatment Effect)가 있는지 확인하는 지표\n\n\n\n\n\n문제 : Counterfactuals (Counter to fact, 일어나지 않은 상황을 가정)\n\n실험 진행 시, 유저는 참여/미참여 중 한 개의 상태로만 존재할 수 있음\n따라서, 실험 당시 미참여 유저가 그렇지 참여한 상황(실제로 일어나지 않음)을 가정\n하지만, 우리는 타임머신이 없기 때문에 동일한 유저에 대해서 2가지 사항을 관측 불가\n→ 인과추론의 근본적인 문제 \n\n\n\nimg\n\n\n\n\n\n\n\n\n하나의 실험 대상에 대해 Treatment에 대한 Potential Outcomes 모두 관찰 불가\n\nSelection Bias 발생하는 이유?\n\n인과추론 근본적인 문제 : Control Group ≠ Counterfactuals\n특성이 다른 다른 대상과 비교 시 Selection Bias가 발생 : &lt;쿠즈다르와 마리아 사례&gt;\n\n결국, 이 문제가 해결이 되어야 Treatment에 따른 인과적인 효과 파악이 가능\n\n\n\n\nIndividual Treatment Effect (ITE) : 개별 유저 i 에 대해 Treatment 처지 효과\n\n유저 i 에게는 2가지 Potential Outcomes이 존재\n\n\\(T = 1\\) : 이벤트 참여 / \\(T = 0\\) : 이벤트 미참여\n2가지 Potential Outcomes 중에서 하나만 존재할 수 있음\n유저 i 에 대한 개별 인과효과 (ITE)\n$ ITE = Y_{0i} - Y_{1i} $\n\n\nAverage Treatment Effect (ATE) : 유저 그룹에 대한 Treatment 처지 효과\n\n유저 개인화 관점에서는 ITE가 이상적이고 중요하지만, 대부분은 유저 그룹단위의 실험이 일반적이며 개개인에 대해 ITE를 파악할 수 없는 경우가 존재\n따라서, 유저 개인의 인과효과를 평균을 내어 집단 레벨에서 설명\n만약, 제대로 된 실험 설계를 하지 않고 ATE를 계산한다면? 아래와 같은 Selection Bias가 생김 &lt;Causal Inference for the brave and true Chapter1. 수식 참조&gt;\n\n$ E[Y|T=1] - E[Y|T=0] = E[Y_1|T=1] - E[Y_0|T=0] + E[Y_0|T=1] - E[Y_0|T=1] $\n$ E[Y|T=1] - E[Y|T=0] = {ATT} + $\n\n\n\n\n\n인과추론의 근본적인 문제를 바라보는 3가지 관점\n\nPotential Outcomes : 물음표 채우기\nStructural Causal Models : DAG\nRegression → 다음 챕터가 Regression인 이유!\n\n오차항 가정(Gaussian Assumption)과 내생성 (Endogenity) → 도구변수 참조\n\n\n\n\n\nSelection Bias 해결하기 위해 이번 챕터에서는 Random Assignment 도입\n\n즉, 실험 대상를 동전던지기로 나눠서 Treatment 여부를 결정\n\n\n\n\nRandom Assignment이 가장 좋은 방법이지만, Research Design 필요성 존재\n\n목적 :\n\n하지만, 항상 주어진 상황에서 RCT를 활용할 수 없는 경우가 많음\n위와 같은 경우, Counterfactual과 최대한 비슷한 Control Group를 실험 디자인을 통해 찾아나가야 함 ↔︎ Selection Bias 줄이기\n\n\n\n\n실험 디자인 방법론 (To be continued)\n\nInstrumental Varibles (2SLS / Regression, Chapter 3)\nRDD (Regression Discontinuity Design, Chapter 4)\nDID (Difference In Difference, Chapter 5)\nSynthetic Control\n\n\n\n\n\n\n\nLLN (Law of Large Numbers) 나오게 된 배경\n\n결국 모집단을 잘 대표하는 표본(Sample)을 선정하기 위해, 충분한 수의 표본이 필요\n궁극적으로, 실험군과 대조군은 동일한 모집단에서 생성 → 그룹간에 비교 가능한 특성을 가져야함 → 해당 조건 달성을 위해서는 충분한 표본이 필요\n과연 Sample Size는 어떤 수준이 적절할까?\n\nStatistical Power(검정력)과 Sample Size\nProduct Active User 규모를 고려\n\n\n\n\n\nHypothesis Testing\n\n목적 : 모집단 (Population Data)의 특성에 대해 설계한 통계적 가설 (\\(H_0\\) / \\(H_1\\))을 모집단의 추출한 샘플 데이터 (Sample Data)를 이용해 검증하는 과정\n인과추론과 가설 검정 : 결국, 인과적인 효과를 추정하기 위해 모집단의 데이터를 활용하는 것보다는 샘플 데이터를 이용해, 개입 (Intervention)에 따른 효과가 있는지 검증\n\n그래서, 후반부에 가설 검정 T-test ↔︎ Two Sample T-test (↔︎ Hausman Test)이 나오게된 것 같음"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#ab-테스트-open-source",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#ab-테스트-open-source",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "A/B 테스트를 할 수 있는 오픈 소스 및 자료\n\n자체 OCE (Online Controlled Experiment) 플랫폼이 있다면 최적의 환경\n실제로 3rd Party 툴 (Amplitude / Braze / Firebase 등)을 통해서 A/B Test를 해볼 수 있음\nGrowthBook과 같이 잘 알려진 오픈 소스를 통해, 현업에 적용이 가능\n오픈 소스 정리자료 링크 : https://posthog.com/blog/best-open-source-ab-testing-tools\n\n\n\n\n실험 플랫폼\n\n직관이 아닌 실험으로의 의사결정은 조직에서 매우 중요한 과제\n참고 도서 : 실리콘밸리의 실험"
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#q-a",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#q-a",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "(종언) 실험에 사용할 샘플 사이즈는 어떻게 가져가는게 좋을까요?\n\n(이삭) : 통계학적인 방법으로는 Statistical Power과 샘플 사이즈가 양의 상관관계가 있어, 검정력을 기준으로 샘플 사이즈가 적절한지 판단하는 것 같습니다,\n(소희) : 적정 샘플 사이즈를 계산해주는 사이트를 사용해봤어요.\n(진수) : 오히려 너무 적은 극단적인 케이스는 Bias가 많고 일반적으로 정상적인 범주에서 벗어났다고 생각해, 실험 대상으로는 제외했던 기억이 있습니다. 원론적인 답변이지만 항상 Product의 Active User 수를 고려해야 할 것 같습니다.\n\n\n\n\n(이삭) 의료 보험 가입으로 건강 증진의 효과를 얻지 못했는데, 미국의 사례여서 그런걸까요?\n\n(정현) : 의료 보험 체계가 다르지만 한국도 비슷하지 않을까 싶습니다. 그런데 실험을 해보지 않아서 직관적인 판단에 주의해야할 것 같아요."
  },
  {
    "objectID": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#reference",
    "href": "posts/entertainment_basic_study_1/1. Randomised Controlled Trial.html#reference",
    "title": "Randomised Controoled Trial",
    "section": "",
    "text": "고수들의 계량경제학 Chapter 1. 무작위 시행 &lt;Joshua D. Angrist , Jorn-Steffen Pischke 저&gt;\nCausal Inference for the brave and true Chapter 1. Introduction to Causality \nKorea Summer Workshop on Causal Inference 2022\nIntroduction to Causal Inference\n유 퀴즈 온 더 블럭 - 구준엽편"
  },
  {
    "objectID": "posts/Chapter_0/0.causal_inference_library.html",
    "href": "posts/Chapter_0/0.causal_inference_library.html",
    "title": "Chapter 0. Causal Inference 라이브러리 정리",
    "section": "",
    "text": "안녕하세요, 가짜연구소 Causal Inference 팀입니다.\n본격적으로 Causal Inference 챕터 공부에 앞서, 학습에 필요한 Library와 튜토리얼을 정리해보았습니다.\n앞으로 Causal Inference 관련된 패키지를 꾸준히 추가할 예정이니, 혹시나 해당 페이지에\n정리되지 않은 라이브러리는 댓글로 달아주시면 감사하겠습니다~!  (Update 22.06.18)\n\n\n\n\n순서\n언어\n라이브러리 명\n설명 & 링크\n\n\n\n\n1\nPython\ncausality\nPython Causality 라이브러리 (Observational Datasets 기반) Github 링크\n\n\n2\nPython\nMicrosoft - DoWhy\nCausal Inference End-to-End 라이브러리 (4단계로 구성) Github 링크/Dowhy 설명자료\n\n\n3\nPython\nMicrosoft - EconML\nHeterogeneous treatment effects 추정 라이브러리 Github 링크\n\n\n4\nPython\nUber - CausalML\nUplift Modeling & ML과 함께 사용할 수 있는 라이브러리 Github 링크\n\n\n5\nPython\nsensemakr\nPython Sensitivity Analysis 라이브러리 설명 링크\n\n\n6\nPython\ncdt\nCausal Discovery 라이브러리 (PC, Skeleton) Github 링크\n\n\n7\nR\nGoogle - CausalImpact\nGoogle에서 베이지안 Time Series 모델을 사용한 R 기반 라이브러리 Github 링크\n\n\n8\nR\nDagitty\nDAG 시각화 및 모델링 라이브러리 Github 링크 / 시각화 연습\n\n\n9\nR\nbnlearn\nDAG 베이지안 네트워크 모델링 라이브러리 Github 링크 /관련 논문 및 코드 소개\n\n\n10\nR\nsensemakr / tipr\nR Sensitivity Analysis 라이브러리 sensemakr 설명 링크 / tipr Github 링크\n\n\n11\nR\nMatchlt\nMatching (PSM)라이브러리 Github 링크\n\n\n12\n공통\ncausaldata\nCausal inference 책에 있는 데이터를 불러오는 라이브러리 Github 링크\n\n\n13\nR\ntlverse\ncausal data science with the tlverse software ecosystem https://tlverse.org/tlverse-handbook/\n\n\n\n\nCausal Inference 라이브러리와 튜토리얼에 대한 정리는\n가짜연구소 Causal Inference 노션 페이지에서도 확인하실 수 있습니다.\n\n\n\nCitationBibTeX citation:@online{2023,\n  author = {, everything},\n  title = {Chapter 0. {Causal} {Inference} {라이브러리} {정리}},\n  date = {2023-10-27},\n  langid = {en}\n}\nFor attribution, please cite this work as:\neverything. 2023. “Chapter 0. Causal Inference 라이브러리\n정리.” October 27, 2023."
  },
  {
    "objectID": "posts/Chapter_1/1.Motivation.html",
    "href": "posts/Chapter_1/1.Motivation.html",
    "title": "Chapter 1. Motivation",
    "section": "",
    "text": "Contents\n\nCausal Inference 란 무엇인가?\n심슨의 역설 (Simpson’s Paradox)\n상관관계는 인과관계를 의미하지 않는다\nCausation in Observational studies\n\n◦ 강의 영상 링크 : Chapter 1 - A Brief Introduction to Causal Inference (Course Preview)\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n\n\n(1) Causal Inference 란 무엇인가?\n\nCausal Inference is concerned with a very specific kind of prediction problem :\nPredicting the results of an action, manipulation, or Intervention\n“Making Things Happen” (2003, Woodwrad)\n\n\n정의 : 현상(문제)에 대한 원인을 찾고 해당 원인에 대한 효과를 추론하는 것\n목표 : 발생한 현상에 대한 ‘Why’ 라는 질문에 대답하는 것 (Causal Structure를 기반으로)\nExample : Effect of \\(X\\) (독립변수) on \\(Y\\) (종속변수)\n\n\n - 이번 할인 이벤트(\\(X\\))로 고과금 PU(\\(Y\\))가 증가한 것 같은데, 어느 정도 효과가 있었을까요?\n - 어떠한 캠페인(\\(X\\))을 노출시키면, CTR(\\(Y\\))를 늘릴 수 있을까요?\n\n\n인과관계의 3가지 단계 (The Ladder of Causation)\n\n\n\nAssociation : \\(P(Y|observe(X))\\) &lt; Supervised Learning &gt;\n    ◦ 관찰된 데이터를 바탕으로 변수간의 연관성을 파악하는 단계 (What If I see ?)\nIntervention : \\(P(Y|do(X))\\) &lt; \\(do\\) : 실험 개입(통제)의 의미 &gt;\n    ◦ 만약 \\(X\\)(개입, 행동)으로 인해, \\(Y\\)(결과)가 어떻게 변화하는지 파악하는 단계\nCounterfactuals (Counter to fact) : 가정법\n    ◦ 가상의 현실 (실제로 관측되지 않는 상황)을 상상하는 단계\n    ◦ 실제로 일어나지 않았지만, 해당 상황이 발생했다면 (\\(X'\\)) 결과(\\(Y\\))가 달라졌을까?\n    ◦ 인과추론의 근본적인 문제 (Fundamental Problem of Causal Inference, 2장)\n\n\n\n\n\n(2) 심슨의 역설 (Simpson’s paradox)\n\n정의 : 데이터를 Subgroup으로 나눠서 보았을 때와 전체 데이터를 합해서 봤을 때,\n           결과가 서로 다른 경우 (통계적 연관성이 유지되지 않는 경우)\n예시 : COVID-27에 대한 치료법\n\n\n◦  목적 : COVID-27에 확진된 환자의 사망율을 낮추는 Treatment (A, B)를 선택\n◦  상황 : 치료법 B는 A보다 더 귀함 (치료법 A를 받는 비중 : 73%, B를 받는 비중 : 27%)\n◦  데이터 해석 : \n    - 데이터 전체로 본 경우 : 치료법 A를 받은 환자 사망율은 치료법 B보다 낮음\n    - Subgroup으로 나눠서 본 경우 : 각 환자 Condition별 사망율은 치료법 A가 B보다 높음\n\n\n◦ 동일한 데이터인데, 결과가 다른 이유는 무엇일까요?\n→ Weighted Sum : 치료법 A, B에 대한 사망율의 각 Condition(Subgroup)에 대한 가중치가 다르기 때문입니다.\n&lt;Non-uniformity of allocation of people to groups&gt;\n\n\n◦ 환자의 사망율을 낮추려면 어떤 치료법을 선택해야 할까요? 환자의 상태를 모른다면, 치료법을 제공할 수 없는 걸까요?\n→ 데이터의 Casual Structure에 따라, 치료법 선택해야 합니다!\n\n\n\n\n(3) 상관관계는 인과관계를 의미하지 않는다\n\nCorrelation : 엄밀하게는 변수간 선형적인 통계적 관계를 의미 (Linear Statistical Dependence)\nSpurious Correlations : 서로 연관성이 없는 변수가 높은 상관관계를 보이는 경우\n\n       → 데이터를 통한 의사결정 과정에서, 잘못된 판단을 하게 만들 수 있습니다\n\n통계학를 배우면 항상 나오는 이야기 입니다. 사례를 통해 이해해보도록 해요!\n사례 1 : 연간 니콜라스 케이지의 영화 출현 횟수와 연간 익사 사망사고 건수 \n\n\n◦  연간 니콜라스 케이지의 영화 출현 횟수와 연간 익사 사망건수는 높은 상관관계를 보입니다.\n◦  그러면, 케이지가 많은 수영하는 사람들이 수영장에 뛰어들도록 부추긴걸까요? No No!\n\n\n\n사례 2 : 신발을 신고 자는 것과 두통으로 일어났을 때 두통을 호소하는 것  \n\n\n◦  상황 : 신발을 신고 자는 것과 두통으로 일어났을 때 두통을 호소하는 것은 큰 상관관계가 존재합니다.\n◦  목표 : 우리는 해당 실험에서, 신발을 신고 자는 것이 일어났을 때 두통을 유발하는 지 인과관계를 찾고 싶어요!\n◦  방해요인 : 두 변수의 공통으로 영향을 주는 변수 &lt; 전날 술을 마신 것 &gt;\n    - Confounder : \\(X\\)(원인)와 \\(Y\\)(결과)에 동시에 영향을 주는 변수\n    - Collider : \\(X\\)(원인)와 \\(Y\\)(결과)에 동시에 영향을 받는 변수\n    → 인과추론을 어렵게 만드는 요인 중 하나입니다.\n◦  What to do? \n  → 일어났을 때 두통이 있는 것(\\(Y\\))의 원인이 신발을 신고 잠에든 경우(\\(X\\))라고 결론을 내리려면, 전날 음주 여부 (Confounder)에 대한 부분을 통제해야 합니다.\n\n\n\nTotal Association = Confounding Association + Causal Association \n→ 이 식을 통해 본 것 처럼, 상관관계는 인과관계를 의미하지 않습니다!\nCorrelation이 Causation과 같다는 것은 Cognitive Bias에 해당합니다. (인지편향, 경험에 의한 비논리적 추론)\n\n\n◦  Availability heuristic : 의사결정 시, 사람의 머릿속에 당장 떠오르는 것에 의존하는 경향\n◦  Motivated Reasoning : 결론에 대한 목표를 정해놓고, 그 주제에 대해서만 생각하는 경향\n◦  해당 인지적 편향으로 인해, 신발을 신고 자서 일어 났을 때 두통이 발생(?)\n◦  Bias : Causation과 Association을 다르게 만드는 요소\n    → 이러한 과정에서 Correlation을 Causation으로 착각하는 오류가 발생하게 됩니다.\n\n\n→ 앞으로 인과추론에 방해되는 요소를 어떻게 통제할 지에 (Bias Adjustment) 대해 학습할 예정이에요!\n\n\n(4) Causation in Observational studies\n→ 관측 환경 (Observational Studies, 통제되지 않은 환경)에서, 인과추론을 어떻게 할까요?\n\n◦  인과추론을 바라보는 관점 : Potential Outcomes (Chapter 2), Causal Models (Chapter4)\n◦  실험 설계 : Experiment Design (Chapter 5, 6)\n◦  인과효과 추정 : IPTW / Meta-Learner (Chapter 7), DID (Chapter 10), IV (Chapter 9) \n◦  그 외에도 여러가지 추정 방법이 존재합니다.\n\n\nTreatment : 인과 효과를 추정하기 위한 원인 변수에 해당 \nTreatment Effect : Treatment에 따른 효과\n\n        ◦ ITE (Individual Treatment Effect) : Treatment에 대한 개개인의 효과를 측정\n        ◦ ATE (Average Treatment Effect) : Treatment에 대한 전체 평균 효과를 측정\n           → 개개인에 대해 ITE를 파악할 수 없는 경우가 존재합니다. 그래서 ATE를 사용하곤 합니다.            \n\n\nObservational Study (관측 연구) vs Experimental Study (실험 연구)\n\n        ◦ Experimental Study : 연구자가 설명변수의 할당 수준에 대해 개입, 조절이 가능\n        ◦ Observational Study : 연구자가 X (설명변수)에 대해 조작, 개입없이 단순히 관찰\n          &lt; ~대부분 Analyst가 분석하는 환경은 Observational Study 이지 않을까요??..~&gt;\n\na. Potential(Counterfactual) Outcomes 관점\n\n정의 : Treatment Option에서 볼 수 있는 모든 잠재적인 결과를 반영한 Causal Effect를 바라보는 관점 \n          &lt; 실제로 관측되지 않은 Counterfactual한 결과도 포함 &gt;\n예시 : \n\n\n사례 1) 광고 노출과 클릭율 \n◦  Treatment : 유저에게 게임 광고 노출 (Treatment Option - 캠페인 A, 캠페인 B)\n◦  Outcome : \\(Y\\_i(1)\\) - 클릭, \\(Y\\_i(0)\\) - 클릭하지 않음\n사례 2) 약과 두통약 \n◦   Treatment : 약을 먹는 경우 - \\(do(T=1)\\) / 약을 먹지 않는 경우 - \\(do(T=0)\\)\n◦   Outcome : \\(Y\\_i(1)\\) - 두통 해소, \\(Y\\_i(0)\\) - 두통 지속\n\n\nCausal Quantity(Estimand, 인과 추정값)와 Statistical Quantity(Estimand, 통계적 추정값) 비교\n\n\n◦  상황 : Causal Quantity는 Counterfactuals로 인해, 직접적으로 계산할 수 없습니다.\n◦  대안 : 해당 부분 대신, Treatment가 주어진 상황에서의 Outcome인 Statistical Quantity로 계산할 수 있어요.\n◦  문제 : Confounding Association으로 Causal Quantity ≠ Statistical Quantity\n    → 그러면, Confounding Association을 어떻게 없애줄 수 있을까요?\n\n◦  해결방법 : Randomized Controlled Trial (RCT)가 해당 부분을 해결하는데 답을 줄 수 있습니다!\n◦  RCT : Control Group (대조군)과 Treatment Group (실험군)을 랜덤하게 할당해,\n             X가 Y에 영향을 미쳤는지 확인하기 위한 실험 설계입니다. (실무에서는 A/B 테스트라고 해요)\n\n◦  RCT 기대효과 : \n     1) 대조군과 실험군의 그룹간 동질성을 가정할 수 있음 (Comparable)\n     2) 잠재적인 Confounder를 평균적으로 동일하게 만들어주는 효과 (Confounder 효과 제거)\n          → 이로 인해, Causal Effect 측정이 가능해 집니다!\n◦  Randomization 어려움 : 매우 이상적이나, 아래 3가지 이유로 항상 Treatment를 랜덤화하는 건 어렵습니다…..\n     1) 윤리적 이유 : 담배를 피지 않는 사람에게, 실험을 위해 담배를 피우게 한다면???\n     2) 실행 가능하지 않음 : Country-level의 실험인 경우, 전세계의 대통령이 되어야해요…\n     3) 불가능 : 암의 효과를 측정하기 위해, 태어날 때 사람의 DNA를 바꾸는 건 불가능합니다…\n     4) 번외로, A/B 테스트를 하는데 자원(시간과 비용)이 많이 들어가요ㅜㅜ\n\n\n\n앞으로 나올 내용 : 관측 환경이 실험 환경과(RCT)비슷하게 끔 만들어 주는 가정에 대해 배웁니다.\n\n       → Identifiability Conditions (Causal Quantity와 Statistical Quantity가 같아지기 위한 조건)\n\n◦   Unconfoundedness : 실험군과 대조군은 교환 (비교) 가능!\n◦   Positivity : Causal Effect를 계산하기 위한 수학적인 가정!\n◦   No Interference : 나의 Outcome은 다른 사람의 Outcome에 영향을 받지 않아야 함!\n◦   Consistency : Treatment에 대해서는 일관된 결과를 보여줘야 함!\n\n\n\nb. Causal Models 관점\n\n정의 : Causal Graph (DAG)를 바탕으로, Causal Effect를 바라보는 관점 \n질문 : \n\n\n\nQ : Causal Model을 바탕으로 Causal Effect를 측정하기 위해 어떠한 방법이 필요할까요?\n     A : Confounding Association이 생기지 않도록 Confounder를 조절/통제하는 방법이 필요해요.\n          아래 그림은 W가 주어졌을 때, Confounding Association이 사라진 부분을 나타내고 있습니다. \n          이 때, W (그림에서는 C)를 Sufficient adjustment set이라고 정의해요\n    → Chapter 3, 4에서 Confounder를 조절하기 위한 방법을 배웁니다! (Back/Frontdoor Adjustment, Do-calculus)\n\nQ : 인과관계를 파악하는 구조를 발견해야 할 것 같은데, 어떻게 발견할 수 있나요?\n     A : 해당 내용은 Causal Discovery (Chapter 11/12)에서 공부할 예정입니다. \n\n\nTo be continued) 앞으로 인과추론의 Framework와 인과 효과를 추정하기 위한 방법에 대해 배울 예정입니다.\n\n\n\nReference\n\n◦ Lecture Notes : 2021 Summer Session on Causal Inference (박지용 교수님) [Link]\n◦ Blog : Individualized treatment effect inference (van der Schaar 교수님, Figure1) [Link]\n\n\n\n\n\nCitationBibTeX citation:@online{shin2023,\n  author = {shin, Jinsoo},\n  title = {Chapter 1. {Motivation}},\n  date = {2023-10-27},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nshin, Jinsoo. 2023. “Chapter 1. Motivation.” October 27,\n2023."
  },
  {
    "objectID": "posts/Chapter_2/2.Potential_Outcomes.html",
    "href": "posts/Chapter_2/2.Potential_Outcomes.html",
    "title": "Chapter 2. Potential Outcomes",
    "section": "",
    "text": "Contents\n\nPotential Outcomes이란 무엇인가요? (aka. Neyman-Rubin Causal model)\n인과추론의 근본적인 문제\n인과추론의 근본적인 문제를 이해하는데 필요한 가정\n\n강의 영상 링크 : Chapter 2 - Potential Outcomes\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n\n\n(1) Potential Outcomes이란 무엇인가요?\n\n정의 : 각각의 Treatment Options 하에서, 볼 수 있는 모든 Outcomes 입니다.\n(같은 실험 대상에서 발생할 수 있는 모든 잠재적인 결과를 고려)\nPotential Outcomes와 Observed Outcomes는 무엇이 다른가요?\n\nObserved Outcomes Y : 실험 대상에게 Treatment를 주었을 때, 발생한 결과\nPotential Outcomes Y(t) : 대상에게 Treatment를 주었을 때, 발생할 수 있는 결과\n→ Observed Outcomes Y ≠ Potential Outcomes Y(t)\n\n모든 Potential Outcomes는 잠재적으로는 관측 가능하나, 모두 관측되는 것은 아니에요!\nPotential Outcomes에 대한 직관\n\n◦  Intuition : 타임머신을 통해 시간을 되돌릴 수 있어서, 그 때 다른 action을 취했더라면 어떻게 되었을까요?\n◦  Example : 타이레놀 복용과 두통 \n    - Factual : 코로나 의심 증상으로 타이레놀을 먹었더니, 두통이 사라졌다\n                                                          &lt; \\(do(T=0)\\)         &lt; \\(Y\\_i(1) = 1\\)&gt;\n    - Counterfactual : 타이레놀을 안먹었더니, 두통이 사라지지 않았다\n                                               &lt; \\(do(T=1)\\)        &lt; \\(Y\\_i(1) = 0\\) &gt;\n    → Potential Outcomes : 두통이 사라진 경우 & 두통이 사라지지 않은 경우\n    → Observed Outcomes : 두통이 사라진 경우  \n      \n    - 타임머신이 있어서 타이레놀 먹기 전으로 돌아갈 수 있어서, 타이레놀을 먹지 않은 경우를 관측할 수 있다면?\n      타이레놀은 나의 두통 해소에 Causal Effect를 측정할 수 있을 거에요!\n      하지만, 현실은 타임머신이 없……죠…….. (인과추론의 근본적인 문제에 해당됩니다)\n◦ Causation은 처치 (Treatment) 이후, Potential Outcomes에 대한 차이로 정의될 수 있습니다. \n\n처치에 대한 인과 효과 = (Treatment 받은 경우에 대한 Observed Outcomes) - (Treatment 받지 않은 경우에 대한 Potential Outcomes)   \n타이레놀에 대한 인과효과 = (타이레놀을 먹은 후, 두통 여부에 대한 관측 결과) - (타이레놀을 먹지 않고, 두통에 대한 잠재적 결과)\n\n\n\n\n(2) Fundamental Problem of Causal Inference\n\nPotential Outcomes에서 본 것 처럼, 각 실험 대상에서 Potential Outcomes을 동시에 관찰하는 것은 불가능해요…!\n즉, 우리에게 ’만약’이라는 데이터 (Counterfactuals)은 존재하지 않습니다.\n\n1) Potential Outcomes에 대해 동시 관측이 불가능 (우린 타임머신 없어요)\n   - 동일한 실험 대상에 Treatment를 다르게 주고, 결과를 두 번 관측해도 될까요? No\n   → 두 번째 결과는 첫 번째 관측 결과에 영향을 받을 수 있습니다. \n2) Causal Effect 계산을 위해, Counterfactuals (Missing values)을 어떻게 해결하는지에 대한 부분이 중요합니다! \n   - 우리가 파악할 수 있는 부분 : Control Group (Treatment를 받지 않은 그룹)\n   - Causal Effect 추정을 위해 필요한 부분 : Counterfactuals (Treatment Group에서 Treatment가 없을 때 결과)\n   → Control Group이 Counterfactuals과 최대한 가깝게 설계해야 합니다.\n\n\n          (후반부의 Ignorability/Unconfoundedness 가정을 확인해주세요!)\n \n3) Selection Bias  : 실험 대상을 랜덤하게 할당 하지 않는 이상, 시스템적으로 발생하는 문제입니다.\n   - Control Group과 Counterfactuals 간의 차이 = Selection Bias\n   - 예시 : 고객에게 노출된 배너 광고를 고객이 볼지 안볼지 선택하는 건 선택 편향 문제를 야기할 수 있어요.\n\n   → 그룹 간 비교 가능하지 않은 상태라면, 광고로 인해 클릭을 (Causal Effect) 했다고 말할 수 없게됩니다.\n\n참고로, 결과가 관측되기 전까지는 Counterfactuals인지 Factuals인지 구분할 수 없습니다. 그래서 관측 전까지 해당 부분은 Potential Oucomes 입니다!\n\n💡 Causal Inference vs Machine Learning\n- Causal Inference : Potential outcomes까지 고려\n- Machine Learning : Potential Outcomes 고려가 필요하지 않고 Observed outcomes만 고려\n\n\n(3) 근본적인 문제를 이해하는데 필요한 가정 \n\nITE 계산의 어려움 : (2)번의 인과 추론의 근본적인 문제(Missing values)에서 보았던 것 처럼,\n개개인에 대한 효과 (ITE)에 대해서 Treatment 효과를 추정하기가 어려운 문제가 생겨요.\nATE 계산 :\n\n1)  Q : 반면, ATE는 구할 수 있을까요? \n      A : Yes, 개인이 아닌 집단에 대한 평균 효과는 구할 수 있어요. \n           집단은 일반적으로 Control Group (대조군) vs Treatment Group (실험군)으로 나누어 측정합니다.\n           엄밀하게 말하면 Statistical Estimand를 구할 수 있습니다! (아래 그림에서는 1/3 이네요)\n\n\nQ : 그런데, 실제로 ATE가 계산이 가능한 걸까요?\n     A : No, 그 이유는 인과추론의 근본적인 문제인 Counterfactuals (Missing values) 때문이에요.\n          위의 그림에서는 Missing values (Selection Bias)를 무시하고 계산한 Statistical Estimand의 결과입니다.\n          하지만, 저희가 필요한 건 Causal Estimand입니다.\n\n                          “Association is not Causation”\n\n   → Selection Bias를 해소하기 위해서는 Control/Treatment 그룹간에 비교가 가능해야 합니다!\n\n\n\nPotential Outcomes Framework의 Missing values 문제를 해결하기 위한 가정을 배워봅시다!\n\n◦ Identification Assumption   \n  →  ATE (Average Treatment Effect)가 Associational Difference와 같아지기 위한 가정     \n     a. (Conditional) Exchangeability = Unconfoundness\n     b. Positivity = Overlap\n     c. No Interference\n     d. Consistency \n\n* SUTVA (Stable Unit-Treatment Value Assumption)   \n\n해당 가정은 No Interference와 Consistency를 결합한 부분이에요.\n\n\n\na1. Exchangeability (Ignorability)\n\n정의 : \\(Treatment \\\\perp (Y(1), Y(0))\\)\n→ Treatment와 발생한 결과(Outcome)은 독립 (Treatment와 관계없이 발생하는 결과는 같습니다!\n\n◦ \\(E[Y(1)|T=0] = E[Y(1)|T=1] = E[Y(1)]\\)\n◦ \\(E[Y(0)|T=0] = E[Y(0)|T=1] = E[Y(0)]\\)\n\n해당 가정을 크게 2가지 관점에서 바라볼 수 있습니다.\n\n◦ Ignorability : 관측되지 않은 Missing values를 고려하지 않아요.\n◦ Exchangeability : Treatment 그룹간은 서로 교환(비교) 가능합니다.\n\n가정의 기대효과\n\n◦ Confounder를(X, 과금수준) 랜덤하게 할당하는 효과를 얻을 수 있습니다 (Random Assignment)\n   = \\(X\\)가 \\(T\\)(프로모션, Treatment)에 할당되는 방식은 Coin Flip과 같아요\n→ 그렇게 되면, Treatment를 제외한 나머지 요인들에 대해, 평균적으로 동질하게 만들어줍니다!\n→ 순수하게 Treatment (프로모션)에 대한 Causal Effect (결제 효과)를 추정 가능하게 해줍니다. \n\n\n문제점 : 다양한 Confounders가 존재하는 현실 상황에서, 두 그룹이 Exchangeable하다고 \n가정하는 것은 다소 비현실적 일 수 있습니다. \n\n\n\na2. Unconfoundedness (Conditional Exchangeability)\n\n등장배경 : 위의 Exchangeability 가정의 문제점에서 말씀드렸던 것 처럼, Observational Study 환경에서는\n현실적이지 않은 가정일 수 있습니다. \n정의 : \\(Treatment|X \\perp (Y(1), Y(0))\\)\n\n 예시 :\n\n◦ 상황 : \\(X\\)(과금 수준)으로 인해, \\(T\\)(프로모션)의 순수한 효과를 알기 어려운 상황입니다.\n◦ 가정 :  Subgroup (고과금, 중과금, 저과금)이 주어졌을 때, Subgroup간 비교가 가능\n◦ 적용 : \\(X\\) (과금 수준)에 대한 Subgroup이 주어졌을 때, 프로모션 그룹은 교환 가능\n   → 이로 인해,  Y (결제)에 대한, Treatment (프로모션)의 효과를 파악할 수 있게 됩니다\n\n계산 방법 : \\(X\\)에 대한 Marginalisation 부분만 추가되고, 나머지는 Exchangeability와 동일합니다!\nConditional Exchangeability 가정을 이용해서 ATE를 구할 수 있습니다.\n\n\n\n문제점 : Unobserved Confounders(\\(W\\))\n\n◦ RCT (Randomized Controlled Trials) 환경이 아니면, 가정이 위배될 수 있습니다.\n◦ 또한 관측되지 않는 교란 변수가 많은 상황에서, Unconfoundedness는 테스트를 할 수 없는 가정이에요.\n    (그래서, 위 가정은 위배되기 쉽습니다ㅜㅜ)\n\n\n\n\nb. Positivity (Common Support)\n\n정의 : \\(0 &lt; P(T=1 |X=x) &lt; 1\\)\n→ 공변량 \\(X\\)이 주어졌을 때, Treatment가 골고루 할당되어야 해요.\n     즉, Treatment를 받은 그룹과 받지 않은 그룹이 특성이 유사해야 합니다!\nPositivity를 보는 다양한 관점\n\n\n조건부 확률 계산 : 해당 Positivity 가정이 없다면, Causal Effect를 추정할 수 없게 됩니다.\n    아래 조건부 확률의 분모 부분이 \\(P(T=1|X=x)\\) 또는 \\(P(T=0|X=x)\\) 0이 되는 문제가 생깁니다…!\n\nOverlap : 어떠한 Covariate \\(X\\)의 분포가 이상적일까요? \n     Treatment가 각각 주어졌을 때, Covariate에 대한 분포가 비슷해야 합니다!\n\n\nPostivity와 Unconfoundedness Tradeoff \n   : Machine Learning에서의 차원의 저주 처럼, Condition하는 Covariate의 차원이 커지면 커질 수록 \n     Overlap이 되는 부분이 점점 줄어들게 됩니다. \n      → 즉, 더 많은 Covariates에 Condition을 줄 수록, Unconfoundedness 가정은 만족하기 쉬워지지만,\n           반대로 차원이 커지게 되어 Overlap (Positivity)가정은 만족하지 못할 확률이 높아집니다.\n\n\n\n\nc. No Interference\n\n정의 : \\(Y\\_i(t\\_1,...,t\\_{i-1},t\\_i,t\\_{i+1}...,t\\_n) = Y\\_i(t\\_i)\\)\n→ 개개인의 Outcome은 다른 사람의 Treatment에 영향을 받지 않아야합니다.\n예시 :\n\n◦ Treatment : 강아지 입양한 경우 - \\(do(T=1)\\) / 입양하지 않은 경우 - \\(do(T=0)\\)\n◦ Outcome : \\(Y\\_i(1)\\) - 행복함, \\(Y\\_i(0)\\) - 행복하지 않음\n◦ 실험 대상 개인의 Treatment에 대한 Outcome(행복)은 주변 대상으로부터 영향을 받지 않아야 해요.\n\n문제점 :\n\n◦ Node간 Connection이 있는 네트워크 데이터에서는 가정이 위배되기 쉽습니다.\n   (서로가 연결이 되어있기 때문이죠!)\n◦ 다른 사람의 영향을 받지 않아야 하지만, 실제로는 받는 경우가 매우 많습니다. 아래 그림 처럼요…….\n\n\n\nd. Consistency\n\n정의 : \\(T=t \\\\Rightarrow Y=Y(t)\\)\n→ 동일한 Treatment의 경우, 그에 따른 결과도 동일해야 합니다\n\n            “There are no multitple versions of Treatment”\n\n예시 : \n\n◦ Teatment : 강아지 입양한 경우 - \\(do(T=1)\\) / 입양하지 않은 경우 - \\(do(T=0)\\)\n◦ Outcome : \\(Y\\_i(1)\\) - 행복함, \\(Y\\_i(0)\\) - 행복하지 않음\n◦ Consistency 가정에 따르면, 강아지를 입양한 경우 \\(do(T=1)\\), 2개의 Outcome (\\(Y\\_i(1)\\), \\(Y\\_i(0)\\)) 중에서 \n    하나의 결과에 대해서만 관측이 되어야 해요.\n     → 아래와 같이 동일한 실험 대상에게 Treatment를 주었을 때, 다른 결과가 나온다면 가정에 위배가 된 것입니다.\n\n\n문제점 : 당연해보이는 가정이지만, 실제 실험에서는 그렇지 않은 경우도 많습니다!\n\n\n\ne. Trying it all together (Identifiability of the ATE)\n\n위에서 배운 4가지 가정을 모두 종합해서, Causal Effect를 Identify 할 수 있어요. \n\n\nTo be continued) 앞으로 인과추론의 다른 Framework인 Strcutural Causal Models에 대해 배울 예정입니다.\n\n\nReference\n◦ Lecture Notes : 2021 Summer Session on Causal Inference (박지용 교수님) [Link]\n◦ Books : 데이터 분석의 힘 (이토 고이치로 저) [Link]\n\n\n\n\nCitationBibTeX citation:@online{shin2023,\n  author = {shin, Jinsoo},\n  title = {Chapter 2. {Potential} {Outcomes}},\n  date = {2023-10-27},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nshin, Jinsoo. 2023. “Chapter 2. Potential Outcomes.”\nOctober 27, 2023."
  },
  {
    "objectID": "posts/Chapter_3/3.Graphical_Models.html",
    "href": "posts/Chapter_3/3.Graphical_Models.html",
    "title": "Chapter 3. Graphical Models",
    "section": "",
    "text": "Contents\n\nGraphical models란 무엇인가요?\nBayesian Networks\nCausal Graphs\nBasic building blocks of graphs\nD-separation\n\n◦ 강의 영상 링크 : Chapter 3 - Graphical Models\n작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n\n\n\n(1) Graphical models란 무엇인가요?\n\nProbabilistic graphical models, which provides a mechanism for exploiting structure in complex distributions to describe them compactly, and in a way that allows them to be constructed and utilized effectively.\n“Probabilistic Graphical Models : Principles and Techniques” (2009, Daphne Koller & Nir Friedman)\n\n\n정의 : 데이터(확률변수)간의 구조를 파악해서 복잡한 분포를 compact하게 표현할 수 있는 방법입니다.\n목표 : \n\n\n◦ 확률 변수간의 구조 표현 : 인과관계 (방향성) or 상관관계\n◦ 복잡한 분포를 표현 : 확률 변수들간의 결합확률분포 (Joint Distribution)\n◦ Compact하게 표현 : 분포를 구성하는 Parameter의 수를 줄이는 방식으로 표현 \n\n\nGraph 정의 : Graphical model을 통해 변수들간의 구조를 시각화한 방법이 Graph 입니다. (Chapter 3에서는요!)\n용어 정리 (Graph Terminology)\n\n\n◦ Graph : 수학적으로 Node와 Edge의 집합입니다. &lt; \\(G = (V, E)\\) &gt;\n◦ Node (Vertex) : Graph에서 주로 변수들을 나타냅니다. ◦ Edge (Link) : Graph에서 변수들간의 관계를 나타냅니다.\n◦ 그래프 방향성 여부에 따라 2가지 형태가 존재합니다.\n    1) Undirected Graph : 아래 Nodes와 Edges 그림 처럼 방향성이 없는 그래프\n         - 예시 : Markov Random Fields, Boltzmann Machine\n    2) Directed Graph : 아래 오른쪽 그림처럼, 화살표가 존재하는 그래프 \n         - 예시 : Bayesian Networks, HMM (Hidden Markov Models), Latent Variable Models\n◦영향을 주는 Node이면 Parent (Ancestor)이고, 받는 Node는 Child (Descendant)라고 정의합니다.\n\n◦ DAG (Directed Acyclic Graph) : Directed graph에서 cycle이 존재하는 경우가 있지만,\n    DAG는 cycle이 없는 방향성 그래프에 해당 합니다.\n     → Cycle이 있는 경우, Causal Inference에서 다루기 까다로워, 해당 강의에서는 DAG만 다룰 예정입니다.\n\n\n\n\n(2) Bayesian Networks\n\n위에서 설명드린 것 처럼, 방향성 그래프에 속하는 Bayesian Networks에 대해서 알아보도록 하겠습니다.\n정의 : 변수 집합의 Dependency 구조와 결합확률분포를 인수분해 방식 (Factorisation)을 통해, 효과적으로 나타내는 Probabilistic graphical models 입니다.\n활용 : DAG가 Bayesian Networks에 속하므로, Causal Model을 활용할 때 사용할 수 있습니다..!\nJoint Distribution 표현 방법 : \n\n\n◦ 변수간의 관계 (association)를 모른다면, 확률 연쇄법칙을 사용해서 다음과 같이 조건부 분포들의\n    (coditional distribution) 곱으로 결합분포를 표현할 수 있어요.\n   - \\(p(x\\_1, \\\\dots, x\\_n) = p(x\\_1)\\\\prod\\_{i=2}^n p(x\\_i | x\\_{i-1}, \\\\dots, x\\_1)\\)\n◦  만약 \\(x\\_i, i=1,\\\\dots, n\\) 가 이항(binary) 변수라면, \\(p(x\\_i | x\\_{i-1}, \\\\dots, x\\_1)\\)은 \\(2^{i-1}\\) 개의 모수가 필요해요.\n     → 결론적으로 조건부 확률에서 조건으로 주어지는 변수가 많아지면 모수가 지수적으로 증가하게 됩니다.\n \n◦  필요없는 변수는 고려하지 말고 영향을 주는 변수만을 골라서 조건으로 준다면, 고려해야하는 경우가 적어지므로\n     필요한 모수가 적어질 것입니다..! \n   - 아래 예시에서 \\((x\\_1, x\\_2, x\\_3)\\)가 주어지는 경우, \\(x\\_4\\) = 1(or \\(x\\_4=0\\))인 확률, 즉 \\(p(x\\_4|x\\_3, x\\_2, x\\_1)\\)만\n     정하면 나머지 확률은 \\(1-p(x\\_4|x\\_3, x\\_2, x\\_1)\\)로 자동으로 정해지게 됩니다.\n     → 따라서, 각 \\((x\\_1, x\\_2, x\\_3)\\) 경우에 1개의 모수만을 필요로 하게 됩니다.\n\n◦  다음 내용에서는 확률 분포의 조건부 독립에 대한 가정에 대해 알아보도록 하겠습니다~!\n\n\nLocal Markov Assumption\n\n\n◦ 정의 : DAG의 Parent가 주어지면, 노드 X는 나머지 descendants가 아닌 노드들과 독립  \n◦ 목적 : Conditional probability를 단순하게 만들기 위해서 입니다..!\n    (마치, Markov chain에서 현재 \\(t\\)시점의 확률분포가 이전 \\((t-1)\\) 시점에만 의존하는 것을 생각하면,\n    이해가 조금 쉬울 것 같습니다! - \\(P(X\\_t|X\\_{t-1}, \\\\dots, X\\_1) = P(X\\_t|X\\_{t-1})\\) )\n◦ 기대효과 : 결합분포에서, 조건으로 주어지는 변수가 줄어 고려해야하는 모수가 줄어들게 됩니다!\n    → \\(P(x\\_1, \\\\dots, x\\_4) = P(x\\_1) P(x\\_2|x\\_1) P(x\\_3 | x\\_2, x\\_1) P(x\\_4|x\\_3)\\)\n\n◦ 예시 : 아래 그림에서 \\(X\\_4\\)는 \\(X\\_3\\)가 조건으로 주어진다면 나머지 변수들과는 조건부 독립이에요.\n    → \\(P(X\\_4|X\\_3,X\\_2,X\\_1) = P(X\\_4|X\\_3)\\)\n◦ 직관 : “지능 → 성적 → 장학금 수여” 이라는 DAG를 생각해봅시다.\n    - 만약 어떤 학생의 성적을 안다면, 그 학생의 지능을 몰라도 장학금을 수여여부를 알 수 있게 됩니다..!\n      \\(P(장학금|지능,성적) = P(장학금|성적)\\)\n\n\nBayesian Network Factoriation (Chain rule for Bayesian networks)\n\n\n◦ 정의 : 확률분포 P와 DAG인 G가 주어졌을 때, G에 따른 P의 Factorisation은 아래와 같습니다.\n    \\(p(x\\_1, \\\\dots, x\\_n) =\\\\prod\\_{i=1}^n p(x\\_i | Pa\\_i)\\)\n◦ Local Markov assumption ⟺ Bayesian network factorization\n    → 위에서 배운 Local Markov assumption과 Bayesian network factorization은 같아요!\n       (해당 부분에 대한 증명은 Probabilistic Graphical Models 책의 Chapter 3 참고 부탁드립니다)\n◦ Local Markov assumption의 한계 : 독립성(독립, 조건부 독립,…)에 대해서만 정보를 제공합니다.\n    → 인접한 Node에 대해서, 종속성 (Dependence)에 대한 보장을 하기 위해서는 조금 더 강한 가정이 필요해요!\n    → 그러면 Minimality assumption에 대해 배워보겠습니다.\n\n\nMinimality assumption\n\n\n◦ 정의 : 해당 가정은 2가지 부분으로 구성되어 있습니다. \n    - Local Markov assumption \n    - Adjacent nodes in the DAG are dependent (DAG에서 인접한 노드들은 의존적이다)\n◦ 차이점 : Local Markov assumption과 비교 \n    - 연결된 노드 X와 Y가 있다고 가정해봅시다.     - Local Markov assumption만 있는 경우, 노드 \\(X\\)와 \\(Y\\)가 있는 경우 \\(P(x,y) = P(x)P(y|x)\\) 뿐만 아니라, \n      \\(P(x,y) = P(x)P(y)\\) 형태도로 인수분해가 가능합니다. (노드 \\(X\\)와 \\(Y\\)가 독립) \n    →  그러나, Minimality assumption에서는 추가적인 독립성 가정을 허용하지 않아요.  \n         (그래서 해당 가정에서는 \\(P(x,y) = P(x)P(y)\\)에 대해 이야기할 수 없어요)\n\n\n\n\n(3) Causal Graphs\n\n위에서 다룬 부분은 DAG의 연관성에 (Association) 대한 부분을 다루었습니다.\n그러나, 저희가 다뤄야할 인과성에 (Causation) 대해서는 추가적인 가정이 필요해요 (Causal assumption)\nCausal Graphs  : Bayesian Networks + 인과성 가정(Causal Edges Assumption) \n\n\n\nWhat is a cause? \n    ◦ 만약 변수 Y가 변수 X의 변화에 ​​따라 변할 수 있다면, X는 Y의 원인이라고 합니다. \n(Strict) Causal Edges Assumption\n    ◦ Directed graph에서, 모든 부모(parent) 노드는 모든 자식(children) 노드의 직접적인 원인입니다.\n    → Minimality assumption의 2번째 가정이(Adjacent nodes in the DAG are dependent)\n        자연스럽게 strict causal edges assumption으로 연결되며, 부모는 자식의 cause라고 특정하는 가정입니다.\n\n3)  Q : 그러면 Strict하지 않은 가정도 있는 건가요? (non-strict assumption)\n     A : 네! 그런데, 우리가 공부할 내용에 대해서는 strict 가정을 만족하는 DAG에 대해서만 다룰 예정이에요\n\n\nAssumptions Flowchart : DAG의 Causal dependencies를 파악하기 위해서 2가지 가정을 배웠습니다!\n\n\n1) Markov Assumption \n    : DAG의 부모 노드가 주어지면, 노드 X는 나머지 descendants가 아닌 노드들과 독립  \n2) Causal Edges Assumption \n    : Directed graph에서, 모든 부모 노드는 모든 자식 노드의 직접적인 원인\n     → 해당 가정은 Minimality Assumption을 내포하고 있어, 위에 Markov Assumption으로 나타냈습니다.\n\n\n\n\n\n(4) Graphical building blocks\n\nDAG에서 그래프를 이루는 구성요소와 흐름에 대해서 배워보려고 해요.\n그래프의 최소 구성 요소 (D-separation 요소)는 Chain, Fork, Immorality 이렇게 3가지로 이루어져 있습니다.\n\n\n\nChains & Forks : 3개의 노드로 구성된 DAG 중 Chain, Fork는 동일한 Dependency 성질을 보입니다.\n\n\n◦  설명 : \n    - \\(X\\_2\\)가 주어지지 않은 경우 :  \\(X\\_1, X\\_3\\)는 직접 연결되어있지는 않지만, 연관성은 존재합니다.\n       → \\(X\\_1\\)에서 \\(X\\_3\\)로 가는 통로가 차단되어 있지 않아, 그대로 정보가 \\(X\\_3\\)까지 흐르게 됩니다.\n            (Unblocked Path)\n    - \\(X\\_2\\)가 주어진 경우 :  \\(X\\_1, X\\_3\\)는 조건부 독립입니다. (연관성은 사라지게 됩니다)\n       → \\(X\\_1\\)에서 \\(X\\_3\\)로 가는 통로가 차단되어 있어,  \\(X\\_1\\)에 있는 정보가 더이상 흐르지 않게 됩니다.\n            (Blocked Path)\n◦  목표 : Causal association이외의 Non-causal association 영향을 제거 (Path 차단)\n    - Chains : Mediator (매개변수)를 통제 \n    - Forks : Confounder (교란변수)를 통제\n\n◦  사례 : \n    - Chains : 위에서 이야기한 사례인 “지능 → 성적 → 장학금 수여” 이라는 DAG를 생각해봅시다.\n       → 만약 성적을 알고 있다면, 지능과 장학금 수여에 대한 연관성은 더이상 존재하지 않게 됩니다!\n            &lt; 성적을 알고 있고, 그에 따라서 장학금을 수여 받게된 것이기 때문이죠 &gt; \n    - Forks : \\(X\\_1, X\\_2, X\\_3\\)가 연관되어 있는 Fork 형태를 선형 모형으로 이해 해봅시다!  \n       → \\(X\\_1 = X\\_2 + \\\\epsilon\\_1\\). \\(X\\_3 = X\\_2 + \\\\epsilon\\_2\\)  \n       → \\(X\\_2 \\\\perp \\\\epsilon\\_1, \\\\epsilon\\_2\\) / \\(\\\\epsilon\\_1 \\\\perp \\\\epsilon\\_2\\)\n       → \\(X\\_2 = x\\) 로 주어진다면, \\(x + \\\\epsilon\\_1 \\\\perp x + \\\\epsilon\\_2\\)\n            즉, \\(X\\_1\\)과 \\(X\\_3\\)는 조건부 독립입니다.!\n\n\nColiders(Immoralities) and their Descendants : \n\n\n◦  Immoralities vs Chains & Forks :  \n    - Immoralities는 앞에서 설명한 Chains과 Forks와 다른 구조를 가집니다.\n    - \\(X\\_1\\)과 \\(X\\_3\\)에 공통으로 영향받는 변수인 \\(X\\_2\\)가 주어진다면, \\(X\\_1\\)과 \\(X\\_3\\)에 연관성이 생기게 됩니다.\n◦  목표 : Causal association이외의 Non-causal association영향을 제거 (Path를 차단하지 않음)\n    - Immoralities : Collider를 통제하게 되면, Association이 형성되므로 통제하지 X \n\n◦  만약 Collider의 자손 (Descendents)이 주어졌다면, 어떻게 될까요?    \n\\(X\\_4\\)가 주어진 경우, \\(X\\_1\\)과 \\(X\\_3\\)는 더 이상 독립이 아니게 됩니다\n\n◦  사례 1 : 잘생긴 사람들은 무례한가요?   \n- \\(X\\_2\\) (연애여부)를 통제하지 않았을 때 : 외모 (\\(X\\_1\\))와 친절함 (\\(X\\_3\\))은 독립에 가깝습니다.   \n- \\(X\\_2\\) (연애여부)를 통제하지 했을 때 : 연애여부를 안다면 (\\(X\\_2\\)),  연애를 하지 않는 사람들은 외모와 친절함과 음의 상관관계를 가지는 것을 확인해볼 수 있습니다…!\n\n\n◦  사례 2 : 아래와 같은 Data Generating Process를 살펴봅시다.\n    - \\(X\\_1\\) ~ \\(N(0,1)\\), \\(X\\_2\\) ~ \\(N(0,1)\\), \\(X\\_2 = X\\_1 + X\\_3\\)\n    - \\(X\\_2\\)가 조건으로 주어지지 않은 경우, 공분산은 0 (독립)\n    - \\(X\\_2\\)가 조건으로 주어진 경우, 공분산은 -1 (음의 상관관계)\n\n\n\n\n\n(5) D-separation\n\n일반적인 인과 모형은 앞에서 배운 Building Blocks (Chains, Forks, Immoralities) 처럼 단순하게 구성되어 있지 않아요.\n따라서 복잡한 인과모형에 적용할 수 있는 규칙에 대해 확인해보도록 하겠습니다.\nD-separation : \n\n\n◦  정의 : 두 노드의 집합 \\(X\\), \\(Y\\) 사이의 모든 경로(Path)가 노드 집합 \\(Z\\)에 의해 차단되는 경우,\n     \\(X\\)와 \\(Y\\)는 \\(Z\\)에 의해 d-separation 된다고 말합니다.\n◦  의미 :    \n- 그래프 상에서 확인할 수 있는 d-separation은 확률분포 상 조건부 독립을 의미해요   \n- d-separation은 Local Markov assumption보다 더 광범위하므로 Global Markov assumption(dependencies) 라고도 해요. 이 경우에는 Local과 Global을 구분하지 않고 Markov assumption이라고 합니다…!\n     → 복잡한 그래프 구조에서 d-separated 되는 경우를 알아야하고 d-separated에서 나오는\n          blocked path를 통해 confounding association 효과를 제거해야 합니다!\n     → Graphical models에서 조건부 독립의 가정/성질(local Markov assumption, d-separated)은\n         확률분포의 분해와 연결됩니다.\n\n◦  예시 : \n    - \\(T\\)와 \\(Y\\)는 \\(\\\\{M\\_1, W\\_2, X\\_2\\\\}\\)가 주어진 경우, d-separated 될까요?    - \\(T\\)와 \\(Y\\)는 \\(\\\\{M\\_1, W\\_2, X\\_1, X\\_2\\\\}\\)가 주어진 경우, d-separated 될까요?\n       → 정답은 댓글로 달아주세요\n\n\nTo be continued) 배운 Causal Graphs를 활용해 일반화된 방법인 Strcutural Causal Models에 대해 배울 예정입니다.\n\n\nReference \n\n◦ Lecture Notes : Bayesian Networks 강의 자료 (카네기 멜론 Uni) [Link]\n◦ Books : Probabilistic graphical models principles and techniques [Link]\n◦ Blogs : Collider 관련 적용 NCSoft 적용 사례 [Link]\n\n\n\n\n\nCitationBibTeX citation:@online{hong2023,\n  author = {hong, seongchul},\n  title = {Chapter 3. {Graphical} {Models}},\n  date = {2023-10-27},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nhong, seongchul. 2023. “Chapter 3. Graphical Models.”\nOctober 27, 2023."
  },
  {
    "objectID": "posts/Chapter_3/3.Graphical_Models.html#graphical-models란-무엇인가요",
    "href": "posts/Chapter_3/3.Graphical_Models.html#graphical-models란-무엇인가요",
    "title": "Chapter 3. Graphical Models",
    "section": "(1) Graphical models란 무엇인가요?",
    "text": "(1) Graphical models란 무엇인가요?\n\nProbabilistic graphical models, which provides a mechanism for exploiting structure in complex distributions to describe them compactly, and in a way that allows them to be constructed and utilized effectively.\n“Probabilistic Graphical Models : Principles and Techniques” (2009, Daphne Koller & Nir Friedman)\n\n\n정의 : 데이터(확률변수)간의 구조를 파악해서 복잡한 분포를 compact하게 표현할 수 있는 방법입니다.\n목표 : \n\n\n◦ 확률 변수간의 구조 표현 : 인과관계 (방향성) or 상관관계\n◦ 복잡한 분포를 표현 : 확률 변수들간의 결합확률분포 (Joint Distribution)\n◦ Compact하게 표현 : 분포를 구성하는 Parameter의 수를 줄이는 방식으로 표현 \n\n\nGraph 정의 : Graphical model을 통해 변수들간의 구조를 시각화한 방법이 Graph 입니다. (Chapter 3에서는요!)\n용어 정리 (Graph Terminology)\n\n\n◦ Graph : 수학적으로 Node와 Edge의 집합입니다. &lt; \\(G = (V, E)\\) &gt;\n◦ Node (Vertex) : Graph에서 주로 변수들을 나타냅니다. ◦ Edge (Link) : Graph에서 변수들간의 관계를 나타냅니다.\n◦ 그래프 방향성 여부에 따라 2가지 형태가 존재합니다.\n    1) Undirected Graph : 아래 Nodes와 Edges 그림 처럼 방향성이 없는 그래프\n         - 예시 : Markov Random Fields, Boltzmann Machine\n    2) Directed Graph : 아래 오른쪽 그림처럼, 화살표가 존재하는 그래프 \n         - 예시 : Bayesian Networks, HMM (Hidden Markov Models), Latent Variable Models\n◦영향을 주는 Node이면 Parent (Ancestor)이고, 받는 Node는 Child (Descendant)라고 정의합니다.\n\n◦ DAG (Directed Acyclic Graph) : Directed graph에서 cycle이 존재하는 경우가 있지만,\n    DAG는 cycle이 없는 방향성 그래프에 해당 합니다.\n     → Cycle이 있는 경우, Causal Inference에서 다루기 까다로워, 해당 강의에서는 DAG만 다룰 예정입니다.\n\n\n\n(2) Bayesian Networks\n\n위에서 설명드린 것 처럼, 방향성 그래프에 속하는 Bayesian Networks에 대해서 알아보도록 하겠습니다.\n정의 : 변수 집합의 Dependency 구조와 결합확률분포를 인수분해 방식 (Factorisation)을 통해, 효과적으로 나타내는 Probabilistic graphical models 입니다.\n활용 : DAG가 Bayesian Networks에 속하므로, Causal Model을 활용할 때 사용할 수 있습니다..!\nJoint Distribution 표현 방법 : \n\n\n◦ 변수간의 관계 (association)를 모른다면, 확률 연쇄법칙을 사용해서 다음과 같이 조건부 분포들의\n    (coditional distribution) 곱으로 결합분포를 표현할 수 있어요.\n   - \\(p(x\\_1, \\\\dots, x\\_n) = p(x\\_1)\\\\prod\\_{i=2}^n p(x\\_i | x\\_{i-1}, \\\\dots, x\\_1)\\)\n◦  만약 \\(x\\_i, i=1,\\\\dots, n\\) 가 이항(binary) 변수라면, \\(p(x\\_i | x\\_{i-1}, \\\\dots, x\\_1)\\)은 \\(2^{i-1}\\) 개의 모수가 필요해요.\n     → 결론적으로 조건부 확률에서 조건으로 주어지는 변수가 많아지면 모수가 지수적으로 증가하게 됩니다.\n \n◦  필요없는 변수는 고려하지 말고 영향을 주는 변수만을 골라서 조건으로 준다면, 고려해야하는 경우가 적어지므로\n     필요한 모수가 적어질 것입니다..! \n   - 아래 예시에서 \\((x\\_1, x\\_2, x\\_3)\\)가 주어지는 경우, \\(x\\_4\\) = 1(or \\(x\\_4=0\\))인 확률, 즉 \\(p(x\\_4|x\\_3, x\\_2, x\\_1)\\)만\n     정하면 나머지 확률은 \\(1-p(x\\_4|x\\_3, x\\_2, x\\_1)\\)로 자동으로 정해지게 됩니다.\n     → 따라서, 각 \\((x\\_1, x\\_2, x\\_3)\\) 경우에 1개의 모수만을 필요로 하게 됩니다.\n\n◦  다음 내용에서는 확률 분포의 조건부 독립에 대한 가정에 대해 알아보도록 하겠습니다~!\n\n\nLocal Markov Assumption\n\n\n◦ 정의 : DAG의 Parent가 주어지면, 노드 X는 나머지 descendants가 아닌 노드들과 독립  \n◦ 목적 : Conditional probability를 단순하게 만들기 위해서 입니다..!\n    (마치, Markov chain에서 현재 \\(t\\)시점의 확률분포가 이전 \\((t-1)\\) 시점에만 의존하는 것을 생각하면,\n    이해가 조금 쉬울 것 같습니다! - \\(P(X\\_t|X\\_{t-1}, \\\\dots, X\\_1) = P(X\\_t|X\\_{t-1})\\) )\n◦ 기대효과 : 결합분포에서, 조건으로 주어지는 변수가 줄어 고려해야하는 모수가 줄어들게 됩니다!\n    → \\(P(x\\_1, \\\\dots, x\\_4) = P(x\\_1) P(x\\_2|x\\_1) P(x\\_3 | x\\_2, x\\_1) P(x\\_4|x\\_3)\\)\n\n◦ 예시 : 아래 그림에서 \\(X\\_4\\)는 \\(X\\_3\\)가 조건으로 주어진다면 나머지 변수들과는 조건부 독립이에요.\n    → \\(P(X\\_4|X\\_3,X\\_2,X\\_1) = P(X\\_4|X\\_3)\\)\n◦ 직관 : “지능 → 성적 → 장학금 수여” 이라는 DAG를 생각해봅시다.\n    - 만약 어떤 학생의 성적을 안다면, 그 학생의 지능을 몰라도 장학금을 수여여부를 알 수 있게 됩니다..!\n      \\(P(장학금|지능,성적) = P(장학금|성적)\\)\n\n\nBayesian Network Factoriation (Chain rule for Bayesian networks)\n\n\n◦ 정의 : 확률분포 P와 DAG인 G가 주어졌을 때, G에 따른 P의 Factorisation은 아래와 같습니다.\n    \\(p(x\\_1, \\\\dots, x\\_n) =\\\\prod\\_{i=1}^n p(x\\_i | Pa\\_i)\\)\n◦ Local Markov assumption ⟺ Bayesian network factorization\n    → 위에서 배운 Local Markov assumption과 Bayesian network factorization은 같아요!\n       (해당 부분에 대한 증명은 Probabilistic Graphical Models 책의 Chapter 3 참고 부탁드립니다)\n◦ Local Markov assumption의 한계 : 독립성(독립, 조건부 독립,…)에 대해서만 정보를 제공합니다.\n    → 인접한 Node에 대해서, 종속성 (Dependence)에 대한 보장을 하기 위해서는 조금 더 강한 가정이 필요해요!\n    → 그러면 Minimality assumption에 대해 배워보겠습니다.\n\n\nMinimality assumption\n\n\n◦ 정의 : 해당 가정은 2가지 부분으로 구성되어 있습니다. \n    - Local Markov assumption \n    - Adjacent nodes in the DAG are dependent (DAG에서 인접한 노드들은 의존적이다)\n◦ 차이점 : Local Markov assumption과 비교 \n    - 연결된 노드 X와 Y가 있다고 가정해봅시다.     - Local Markov assumption만 있는 경우, 노드 \\(X\\)와 \\(Y\\)가 있는 경우 \\(P(x,y) = P(x)P(y|x)\\) 뿐만 아니라, \n      \\(P(x,y) = P(x)P(y)\\) 형태도로 인수분해가 가능합니다. (노드 \\(X\\)와 \\(Y\\)가 독립) \n    →  그러나, Minimality assumption에서는 추가적인 독립성 가정을 허용하지 않아요.  \n         (그래서 해당 가정에서는 \\(P(x,y) = P(x)P(y)\\)에 대해 이야기할 수 없어요)\n\n\n\n\n(3) Causal Graphs\n\n위에서 다룬 부분은 DAG의 연관성에 (Association) 대한 부분을 다루었습니다.\n그러나, 저희가 다뤄야할 인과성에 (Causation) 대해서는 추가적인 가정이 필요해요 (Causal assumption)\nCausal Graphs  : Bayesian Networks + 인과성 가정(Causal Edges Assumption) \n\n\n\nWhat is a cause? \n    ◦ 만약 변수 Y가 변수 X의 변화에 ​​따라 변할 수 있다면, X는 Y의 원인이라고 합니다. \n(Strict) Causal Edges Assumption\n    ◦ Directed graph에서, 모든 부모(parent) 노드는 모든 자식(children) 노드의 직접적인 원인입니다.\n    → Minimality assumption의 2번째 가정이(Adjacent nodes in the DAG are dependent)\n        자연스럽게 strict causal edges assumption으로 연결되며, 부모는 자식의 cause라고 특정하는 가정입니다.\n\n3)  Q : 그러면 Strict하지 않은 가정도 있는 건가요? (non-strict assumption)\n     A : 네! 그런데, 우리가 공부할 내용에 대해서는 strict 가정을 만족하는 DAG에 대해서만 다룰 예정이에요\n\n\nAssumptions Flowchart : DAG의 Causal dependencies를 파악하기 위해서 2가지 가정을 배웠습니다!\n\n\n1) Markov Assumption \n    : DAG의 부모 노드가 주어지면, 노드 X는 나머지 descendants가 아닌 노드들과 독립  \n2) Causal Edges Assumption \n    : Directed graph에서, 모든 부모 노드는 모든 자식 노드의 직접적인 원인\n     → 해당 가정은 Minimality Assumption을 내포하고 있어, 위에 Markov Assumption으로 나타냈습니다.\n\n\n\n\n\n(4) Graphical building blocks\n\nDAG에서 그래프를 이루는 구성요소와 흐름에 대해서 배워보려고 해요.\n그래프의 최소 구성 요소 (D-separation 요소)는 Chain, Fork, Immorality 이렇게 3가지로 이루어져 있습니다.\n\n\n\nChains & Forks : 3개의 노드로 구성된 DAG 중 Chain, Fork는 동일한 Dependency 성질을 보입니다.\n\n\n◦  설명 : \n    - \\(X\\_2\\)가 주어지지 않은 경우 :  \\(X\\_1, X\\_3\\)는 직접 연결되어있지는 않지만, 연관성은 존재합니다.\n       → \\(X\\_1\\)에서 \\(X\\_3\\)로 가는 통로가 차단되어 있지 않아, 그대로 정보가 \\(X\\_3\\)까지 흐르게 됩니다.\n            (Unblocked Path)\n    - \\(X\\_2\\)가 주어진 경우 :  \\(X\\_1, X\\_3\\)는 조건부 독립입니다. (연관성은 사라지게 됩니다)\n       → \\(X\\_1\\)에서 \\(X\\_3\\)로 가는 통로가 차단되어 있어,  \\(X\\_1\\)에 있는 정보가 더이상 흐르지 않게 됩니다.\n            (Blocked Path)\n◦  목표 : Causal association이외의 Non-causal association 영향을 제거 (Path 차단)\n    - Chains : Mediator (매개변수)를 통제 \n    - Forks : Confounder (교란변수)를 통제\n\n◦  사례 : \n    - Chains : 위에서 이야기한 사례인 “지능 → 성적 → 장학금 수여” 이라는 DAG를 생각해봅시다.\n       → 만약 성적을 알고 있다면, 지능과 장학금 수여에 대한 연관성은 더이상 존재하지 않게 됩니다!\n            &lt; 성적을 알고 있고, 그에 따라서 장학금을 수여 받게된 것이기 때문이죠 &gt; \n    - Forks : \\(X\\_1, X\\_2, X\\_3\\)가 연관되어 있는 Fork 형태를 선형 모형으로 이해 해봅시다!  \n       → \\(X\\_1 = X\\_2 + \\\\epsilon\\_1\\). \\(X\\_3 = X\\_2 + \\\\epsilon\\_2\\)  \n       → \\(X\\_2 \\\\perp \\\\epsilon\\_1, \\\\epsilon\\_2\\) / \\(\\\\epsilon\\_1 \\\\perp \\\\epsilon\\_2\\)\n       → \\(X\\_2 = x\\) 로 주어진다면, \\(x + \\\\epsilon\\_1 \\\\perp x + \\\\epsilon\\_2\\)\n            즉, \\(X\\_1\\)과 \\(X\\_3\\)는 조건부 독립입니다.!\n\n\nColiders(Immoralities) and their Descendants : \n\n\n◦  Immoralities vs Chains & Forks :  \n    - Immoralities는 앞에서 설명한 Chains과 Forks와 다른 구조를 가집니다.\n    - \\(X\\_1\\)과 \\(X\\_3\\)에 공통으로 영향받는 변수인 \\(X\\_2\\)가 주어진다면, \\(X\\_1\\)과 \\(X\\_3\\)에 연관성이 생기게 됩니다.\n◦  목표 : Causal association이외의 Non-causal association영향을 제거 (Path를 차단하지 않음)\n    - Immoralities : Collider를 통제하게 되면, Association이 형성되므로 통제하지 X \n\n◦  만약 Collider의 자손 (Descendents)이 주어졌다면, 어떻게 될까요?    \n\\(X\\_4\\)가 주어진 경우, \\(X\\_1\\)과 \\(X\\_3\\)는 더 이상 독립이 아니게 됩니다\n\n◦  사례 1 : 잘생긴 사람들은 무례한가요?   \n- \\(X\\_2\\) (연애여부)를 통제하지 않았을 때 : 외모 (\\(X\\_1\\))와 친절함 (\\(X\\_3\\))은 독립에 가깝습니다.   \n- \\(X\\_2\\) (연애여부)를 통제하지 했을 때 : 연애여부를 안다면 (\\(X\\_2\\)),  연애를 하지 않는 사람들은 외모와 친절함과 음의 상관관계를 가지는 것을 확인해볼 수 있습니다…!\n\n\n◦  사례 2 : 아래와 같은 Data Generating Process를 살펴봅시다.\n    - \\(X\\_1\\) ~ \\(N(0,1)\\), \\(X\\_2\\) ~ \\(N(0,1)\\), \\(X\\_2 = X\\_1 + X\\_3\\)\n    - \\(X\\_2\\)가 조건으로 주어지지 않은 경우, 공분산은 0 (독립)\n    - \\(X\\_2\\)가 조건으로 주어진 경우, 공분산은 -1 (음의 상관관계)\n\n\n\n\n\n(5) D-separation\n\n일반적인 인과 모형은 앞에서 배운 Building Blocks (Chains, Forks, Immoralities) 처럼 단순하게 구성되어 있지 않아요.\n따라서 복잡한 인과모형에 적용할 수 있는 규칙에 대해 확인해보도록 하겠습니다.\nD-separation : \n\n\n◦  정의 : 두 노드의 집합 \\(X\\), \\(Y\\) 사이의 모든 경로(Path)가 노드 집합 \\(Z\\)에 의해 차단되는 경우,\n     \\(X\\)와 \\(Y\\)는 \\(Z\\)에 의해 d-separation 된다고 말합니다.\n◦  의미 :    \n- 그래프 상에서 확인할 수 있는 d-separation은 확률분포 상 조건부 독립을 의미해요   \n- d-separation은 Local Markov assumption보다 더 광범위하므로 Global Markov assumption(dependencies) 라고도 해요. 이 경우에는 Local과 Global을 구분하지 않고 Markov assumption이라고 합니다…!\n     → 복잡한 그래프 구조에서 d-separated 되는 경우를 알아야하고 d-separated에서 나오는\n          blocked path를 통해 confounding association 효과를 제거해야 합니다!\n     → Graphical models에서 조건부 독립의 가정/성질(local Markov assumption, d-separated)은\n         확률분포의 분해와 연결됩니다.\n\n◦  예시 : \n    - \\(T\\)와 \\(Y\\)는 \\(\\\\{M\\_1, W\\_2, X\\_2\\\\}\\)가 주어진 경우, d-separated 될까요?    - \\(T\\)와 \\(Y\\)는 \\(\\\\{M\\_1, W\\_2, X\\_1, X\\_2\\\\}\\)가 주어진 경우, d-separated 될까요?\n       → 정답은 댓글로 달아주세요\n\n\nTo be continued) 배운 Causal Graphs를 활용해 일반화된 방법인 Strcutural Causal Models에 대해 배울 예정입니다.\n\n\nReference \n\n◦ Lecture Notes : Bayesian Networks 강의 자료 (카네기 멜론 Uni) [Link]\n◦ Books : Probabilistic graphical models principles and techniques [Link]\n◦ Blogs : Collider 관련 적용 NCSoft 적용 사례 [Link]"
  },
  {
    "objectID": "posts/Chapter_4/4.Causal_Models.html",
    "href": "posts/Chapter_4/4.Causal_Models.html",
    "title": "Chapter 4. Causal Models",
    "section": "",
    "text": "Contents\n\nDo-operator and Interventional Distributions\nModularity Assumption\nBackdoor adjustment\nStructural causal models\n\n◦ 강의 영상 링크 : Chapter 4 - Causal Models\n    작성된 내용 중 개선점이나 잘못된 부분이 있다면 댓글로 알려주세요!\n◦ 이번 강의는 아래의 내용을 다룰 예정입니다.\n     Casual Inference를 할 때, 이론적으로 대답할 수 없는 Causal Estimand를 여러가지 가정을 통해 계산할 수 있는\n     Statistical Estimand로 추정하게 됩니다. 이때 필요한 개념인 Causal Model에 대해서 학습합니다.\n\n\n\n\n(1) Do-operator란 무엇인가요?\n\n정의 : 주어진 현상을 그대로 관찰하는게 아닌, 더 나아가 “개입한다”라는 것을 표현하는 수학 연산자입니다.\n                                                                                   (Intervention)\n역할 : Do-operator를 통해, Treament에 영향을 줄 수 있는 모든 요인의 효과를 무시할 수 있게 됩니다. \n                                                       (Treatment의 부모 노드)\nConditioning (조건) vs Intervention (개입) \n\n\n◦ Conditioning on \\(T=t\\) : 전체 모집단 or 관측한 데이터에서 Treatment \\(t\\)를 받은 모집단의 부분 집합에 해당합니다.\n◦ Intervention on \\(T=t\\) : 처치한 부분 집합이 아닌, 전체 모집단에 대해서 \\(T=t\\) 로 설정한 것을 말합니다.\n     - 통상적으로 Intervention은 \\(do(T=t), do(t)\\)로 표현합니다.\n     - 이는 주어진 현상을 그대로 관찰하는 것이 아닌, Doing(개입)한다라는 의미로 이해할 수 있습니다.\n◦ 아래와 같이 Conditioning과 Intervention은 서로 다른 표현방식이므로, 다른 데이터 분포를 형성합니다.\n\n\n\n\nObservational Distribution vs Interventional Distribution\n\n\n◦ Observational distribution \n     - 표현 : \\(P(Y),P(Y,T,X)\\)     - 특징 : 개입(doing)이 없이, 생성된 분포를 Observational distribution이라 합니다.\n◦ Interventional distribution \n     - 표현 : \\(P(Y|do(T=t)),P(Y|do(T=t),X=x))\\)\n     - 특징 : Treatment에 대한 개입 (do-operator)이 존재합니다. \n        →  처치(\\(T\\))를 통해 Randomized trial실험과 같은 효과를 낼 수 있으며, 이러한 데이터를 통해 추정된 인과 효과를\n              Causal Estimand라고 합니다.\n         → 반면, do-operator를 포함하지 않은 추정치 (Estimand)는 Statistical Estimand라고 합니다.     - 예시 : \\(P(Y|do(T=t),Z = z)\\)가 의미하는 것은 무엇일까요?\n       → 모집단에 대해서 \\(T=t\\)에 대한 개입을 받은 Z=z인 부분집합에 해당하는 데이터라고 할 수 있습니다.\n\n\nIdentifiability :\n\n◦ 정의 : 개입을 통해 얻은 Causal Estimand를 Identification 가정을 통해 Statistical Estimand로 바꾸는 과정\n                           (직접 계산할 수 없음, Counterfactuals)                               (직접 계산가능)           \n    → 이 때, Confounders \\(X\\)를 제어하는데 필요한 Causal Models의 요소를 이번 Chapter에서 배울 예정입니다!\n\n\n(참고) Do-operator\n여기서 Do-operator는 쉽게 말해서 “개입한다”라는 의미입니다. 다시말해서 Do-operator의 역할은, Treament에 영향을 줄 수 있는 모든 변수의 효과를 무시하게 만들어줍니다.\n\n여기서 \\(P(Y|X)\\)는 인과효과가 아니에요. 왜냐하면 Confounder로 인한, Backdoor path가 열려 있기 때문이죠.\nDo-operator를 적용하면, X에 영향을 주는 C→ X 사이의 연결고리를 그래프 상에서 이론적으로 없애는 것이며,이 상태에서 계산한 \\(P(Y|do(X))\\) 값이 바로 인과 효과라는 것입니다.\n\n이러한 Do-operator는 실제 계산할 수 있는 값이라기 보다는 이론적인 개념이며, 그래서 결국 Do-operator를 수학적으로 계산할 수 있는 조건부 확률로 만들어줘야 하는데, 이때 필요한 가정을 앞에서 배운 Identification 입니다.\n“정리하자면, Interventional probability를 통해 Casual effect를 정의하고, Identifiable인지를 통해서 실제로 추정 가능한지에 대해 판단하며, 이를 통해 인과 관계를 구해보자는 것이죠”\n\n\n(2) Modularity Assumption\n\n앞으로 Identification을 하기 위해서 가정이 필요한데요, 해당 가정에 대해 배워보도록 할게요!\nCausal Indentification를 하기 위한 중요한 가정 : Interventions are local\n그러면, Interventions are local이 무엇일까요?\n\n\n◦  의미 : 어떤 노드에 개입(Intervention)하게 되면, 개입으로 인한 변화가 local하다는 것입니다.\n◦  효과 : 즉, 개입한 노드 \\(X\\_i\\)에 대해서 부모 노드 \\(pa\\_i\\)가 미치는 영향만 변하고,\n     나머지 노드에서 주는 영향은 유지가 된다라는 것입니다.\n◦  예시 : 아래 그림에서, 해당 가정에 따르면 원 안에 있는 \\(X\\_i\\)의 부모 노드(\\(pa\\_i\\))가 미치는 영향만 변화하고,\n     나머지는 영향은 유지 됩니다.\n\n\n\nModularity assumption : Interventions are local을 일반화한 가정\n\n\n◦ 정의 : \n\n   어떤 Graph 상 n개의 노드가 존재하고, 그 중 개입(intervention)을 한 노드의 인덱스 집합을 S라고 한다면,\n    1. 노드 i가 개입되지 않은 경우 (\\(i∉S\\)) 노드 i (\\(X\\_i\\))의 부모 노드(\\(pa\\_i\\))가 노드 \\(i\\)에 미치는 영향은 그대로 유지\n    2. 노드 i가 개입되었다면 (\\(i∈S\\)), \\(x\\_i\\)값으로 개입한 경우 \\(P(x\\_i|pa\\_i)\\) = 1,\n                                                          \\(x\\_i\\)값으로 개입하지 않은 경우 \\(P(x\\_i|pa\\_i)\\) = 0\n     * [n] = 1,2,3,4…,n 이며 각 숫자는 노드의 index를 의미\n        \\(X\\_i\\): Index가 i인 노드를 의미, \\(x\\_i\\) : 값(scalar)을 의미\n\n◦ Assumption violation : 그러면, Modularity 가정이 위배된다는 것은 어떤 의미일까요?\n     - 노드 \\(T\\) 에 대한 개입(intervention)이 \\(T\\)의 부모 노드에 대한 영향력에 변화를 줄 뿐만 아니라,  \n       \\(T\\_2\\)의 부모 노드에 대해 변화를 주었을 때, “Intervention이 local이 아니다”라고 합니다.\n\n◦ 예시 : \n    (a) 개입이 없는 Observational distribution\n    (b) \\(T\\)에 개입 : \\(T\\)의 부모 노드에서 오는 영향만 사라지고, 나머지는 유지됩니다.\n    (c) \\(T\\_2\\)에 개입 : \\(T\\_2\\)의 부모 노드에서 오는 영향이 사라지고, 나머지는 유지됩니다.\n     → \\(P(Y)\\), \\(P(Y|do(T=t))\\), \\(P(Y|do(T\\_2=t\\_2))\\)는 서로 연관되지 않은 완전히 다른 분포가 됩니다.\n     → (b), (c) 처럼 edge가 제거된 그래프를 Manipulated graph라고 해요!\n\n\n\n\nTruncated factorization\n\n\n◦ 우리는 방금 배운 Modularity assumption을 통해 새로운 식을 추론해낼 수 있어요. \n◦ 정의 : Bayesian network factorization에서 modularity assumption이 적용된 식입니다. \n◦ 과정 : 그럼 지난 시간에 배운 내용을 Remind 해볼까요?\n    1. Bayesian network factoriazation\n         = Chain rule of probability + Markov assumption\n\n        - Chain rule of probability : \\(P(x,y) = P(x)⋅P(y|x)\\)\n        - Markov assumption : 모든 노드는 오직 부모 노드로부터 영향을 받습니다.\n    2. Modularity assumption 적용\n       여기서 개입(intervention)을 한 노드의 인덱스 집합을 S라고 한다면, \\(i∈S\\) 인 노드들에 대해서는,\n       \\(P(x\\_i|pa\\_i)\\) = 1이기 때문에, bayesian network factorization 계산 과정에서 생략이 가능합니다.\n      →  따라서 \\(i∉S\\)인 노드들에 대해서만 \\(P(x\\_i|pa\\_i)\\)를 계산하면 되며, bayesian network factorization\n           식에서 아래와 같은 식을 도출할 수 있습니다.\n \n\n◦ 예시 : \\(P(y|do(t))\\)를 Identify 해봅시다.    → Treatment \\(T\\)에 영향을 미치는 부분이, 제거 (Trucated) 됩니다.\n\n\n\n\n(3) Backdoor adjustment\n\n이전 내용에서 개입(Doing)을 통해서 Treatment에 영향을 주는 외부 변수(Backdoor)를 차단하면서\nCasual effect를 구할 수 있다고 했습니다.\n\n\n\nQ : 그러면, Observational data에서 어떻게 Causal effect를 구할 수 있을까요?\n     A : 관측 데이터인 observational data에서는 개입(intervention)을 통해 그래프를 마음대로 변경하기는 어려워요.\n             하지만 아래 그림과 같이 Observational data의 Graph에 조건을 추가한다면, \\(P(Y|do(X))\\)와 동일한 효과를\n             줄 수 있지 않을까요?\n\n    * 아래 그래프에서의 Backdoor Paths (Non-causal association)\n       ◦ \\(T - W - Y\\)\n       ◦ \\(T - C - Y\\)\n\n\nQ : 그렇다면 어떠한 조건을 통해, Observation data에서 Doing(개입)한 것과 동일한 효과를 낼 수 있을까요?\n     A : Observation data Graph에 추가할 조건에 대한 기준이 필요합니다. 해당 조건을 정리한 것이 바로,\n           Backdoor criterion입니다.\n\n\n\nBackdoor Criterion :\n\n\n◦ 정의 : $T → Y $간의 Causal association을 제외한 모든 Backdoor paths를 막을 수 있는 변수들의 집합 \\(W\\)\n◦ 조건 :\n   1. 집합 W는 T에서 Y로 가는 모든 Backdoor paths를 block\n   2. 집합 W는 T의 어느 자손도 포함하지 말아야 함\n◦ Sufficient adjustment set : Modularity 가정이 주어졌을 때, 변수들의 집합 \\(W\\)가 Backddor Criterion을\n    만족한다면, \\(W\\)를 Sufficient adjustment set이라고 합니다.\n◦ 의미 : \\(W\\)가 Backdoor Criterion을 만족하게 되면, \\(T\\)에 대한 \\(Y\\)의 Causal Effect를 Identify 할 수 있어요!\n◦ 예시 :     1.  만약 confounder가 있다면, confounder를 통제를 해야 backdoor path를 막을 수 있습니다.         이러한 confounder의 집합이 backdoor criterion을 만족하는 집합이라고 볼 수 있겠죠. \n    2. 반면에 collider는 통제하면 안됩니다.         따라서 이러한 collider는 backdoor criterion을 만족하는 집합이라고 볼 수 없습니다.\n     → 즉, 우리가 해야하는 것은 backdoor criterion을 만족하는 모든 집합을 통제해야해요!\n◦ 증명 : 그렇다면 정말 Backdoor adjustment를 통해 Doing(개입)의 효과를 얻을 수 있을까요?\n    1.  \\(P(Y|do(t),W)=P(Y|T,W)\\)  &lt; line 1 to line 2 &gt;\n          - Backdoor criterion 1번 조건에 의해 \\(W\\)는 모든 backdoor paths를 차단합니다.\n          → 따라서, \\(T\\)로 들어오는 edge의 영향이 제거 됩니다!          - 좌변 : \\(do(t)\\)의 modularity assumption에 의해 \\(T\\)에 들어오는 edge의 영향이 제거\n          - 우변 : \\(W\\)를 condition함으로써, \\(T\\)로 들어오는 edge의 영향을 제거\n    2.  \\(P(W|do(t)) = P(W)\\) &lt; line 2 to line 3 &gt;\n          - \\(T=t\\) 라고 통제를 했으므로, \\(W\\)→\\(T\\) 관계가 사라집니다. (독립)\n          →  따라서, Backdoor adjustment를 통해 observational data를 가지고 앞에서 Casual로 정의한         \n               \\(P(Y|do(t))\\)를 규명할 수 있습니다.\n\n\n\nBackdoor Criterion과 D-separation : D-separation을 backdoor criterion 가지고 정의해봅시다.\n\n\n1. Backdoor criterion &lt; 왼쪽 그림 &gt;\n     - 조건 1. 집합 \\(W\\)는 \\(T\\)에서 \\(Y\\)로 가는 모든 backdoor paths를 막아야합니다.\n                   열려 있는 Backdoor path는 \\(W\\_2\\) or \\(W\\_1\\)→ Blocked\n     - 조건 2. 집합 \\(W\\)는 \\(T\\)의 어느 자손도 포함하지 말아야 합니다.\n                   \\(T\\)의 자손인 \\(X\\_2\\)가 막혀 있습니다. → Unblocked\n2.  Backdoor adjustment 처리 된 그래프 \\(G\\) &lt; 가운데 그림 &gt;\n     - 그리고 단 하나의 Association도 존재하지 않는 조건부 독립을 의미하는 D-separated는 \\(T\\)→\\(M\\_1\\)으로 가는\n       edge를 제거하게 됩니다.\n3. D-separation &lt; 오른쪽 그림 &gt;\n     - 이렇게 하여 생성된 그래프를 아래 그림과 같이 \\(G\\_{\\\\bar{T}}\\)로 표현하고, \\(W\\) 컨디션 아래에서 \\(Y\\)와 \\(T\\)는\n       d-separated 되었다고 표현합니다.\n\n\n\n\n(4)Structural causal models (구조적 인과 모델)\n\n구조적 인과모델 (Structural Casual Model)은 변수들 사이의 인과 관계를 구조화 된 함수로 나타내는 것입니다.\n표현 : 수학에서 쓰는 ‘=’ 과는 달리, causation 상에서는 역이 성립하지 않으며, 아래와 같이 표기합니다.\n◦  Structural equation B := f(A)\n◦ 여기서 A와 B 의 mapping이 deterministic 합니다. 명확한 관계가 이외의 확률적인 부분 (Stochastic)을\n    고려하기 위해선 B의 unknown causes도 인지해야 해요. 그래서 해당 변수를 고려하면 아래와 같습니다.\n    →  B := f(A,U)\n\n\n\nStructural Casual Models\n\n\n◦ 정의 : Structural causal models은 다음 3개의 집합에 대한 튜플(Tuple)입니다.\n    1.  U : 외생(exogenous) 변수, 모델 밖에서 그 값이 결정되는 변수들의 집합\n         - 부모 노드가 없는 변수로 이 노드의 causes를 모델링 할 필요가 없습니다.\n         - 아래 그림에서는 변수 \\(U\\_B, U\\_C, U\\_D\\)에 해당합니다.\n    2.  V : 내생(endogenous) 변수, 모델 내에서 다른 변수들에 의해 설명되는 집합\n         - 부모노드가 존재하는 변수로 모델링 하고자하는 structural equation의 변수\n         - 아래 그림에서는 변수  $ B, C, D$에 해당합니다.\n    3.  f : 모델 내 다른 변수들에 따라 V에 속한 변수들의 값을 결정하는 함수 집합\n\n◦ Structural Causal Model (SCM)를 쓰는 이유가 무엇일까요?\n    1. Potential Outcomes 표현\n         - SCM에서 \\(T=t\\)로 고정했을때 나오는 결과 값은 potential outcome 입니다.\n    2. 일반화된 분포 고려 가능\n         - DAG로 표현 시, Causal direction이 다를 수 있어 인과관계를 확인하기에 적합하지 않아요.\n           하지만 SCM은 DAG의 구조적 할당을 따르며 SEM (Strctural Equation Models)의 functional form을\n           통해, intervention set을 지정할 수 있습니다. 따라서, 더 많은 상황에서의 분포를 고려할 수 있어요.\n    3. Causal Models 체계화 \n         - 그래프 기반으로 인과관계를 분석하는 건 간단하지만 이런 그래프가 복잡해지면 직관적인 이해만으론 한계가\n           존재합니다. 그렇기 때문에, 그래프 기반의 인과관계 분석을 수학적인 언어를 통해 보다 체계화 할 수 있어요.\n◦ 예시 : 아래 그래프를 SCM 구조로 표현해봅시다.\n    - \\(U=\\) {\\(X\\)}, \\(V=\\) {\\(T,Y\\)}, \\(F=\\) {\\(f\\_T,f\\_Y\\)}    - \\(f\\_T:=\\\\alpha\\_1X\\)\n    - \\(f\\_Y:=\\\\beta T+\\\\alpha\\_2X\\)\n\n\n\n SCMs에서의 Intervention : Modularity assumption에 의해 SCM(M)과 Interventional SCM(\\(M\\_t\\))에는 \\(M\\_t\\)에서 개입이 일어나는 변수 \\(T\\)에 대한 구조방정식이 T:=t로 대체되는 것 외, 개입이 일어나지 않는 다른 변수에 대한 구조 방정식은 동일합니다.\n\n\n\nThe Law of Counterfactuals (and Interventions)\n\n\n◦ 정의 :  \\(Y\\_t(u) = Y\\_{M\\_t}(u)\\)\n◦ 의미 : SCM에 대한 충분한 정보가 있는 경우, 실질적으로 Counterfactuals을 계산 할 수 있다는 Principle입니다.\n◦ 의의 : Chapter 2에서 이야기한 인과추론의 근본적인 문제이기 때문입니다. \n    해당 내용은 Chapter 14에서 더 세부적으로 다룰 예정이에요.\n\n\nCollider과 Treatment의 자식노드는 왜 Condition을 하지 않을까요?\n\n\n\nCausation을 막기 때문입니다.\n    ◦ 왼쪽 그림 : 아래 그림은 \\(T\\)와 \\(Y\\)가 d-seperarted되어, 모든 causation이 막힌 상황입니다.\n    ◦ 오른쪽 그림 : Causation이 있기 위해서는 \\(T\\)와 \\(Y\\) 사이에 direct path가 있으면 됩니다.\n        → 이러한 blocking causal association 이유로 descendants of treatment를 condition 하지 않습니다.\n\n\n\n새로운 형태의 Association이 생기기 때문입니다 : new post-treatment association\n    ◦오른쪽 그림 : \\(M\\)에서 관측되지 않은 외생변수 \\(U\\_M\\)과 \\(T\\), \\(M\\)사이엔 collider가 있다고 볼 수 있어요.\n       → collider의 자식 노드인 \\(Z\\)를 condition하면, 새로운 post-treatment association이 발생할 수 있습니다!\n \n\n새로운 형태의 Association이 생기기 때문입니다 : new pre-treatment association &lt; M-bias &gt;\n    ◦ 아래 그림에서도 \\(Z2\\) 가 collider이므로, M-bias 형태에서 conditioning 시킬 수 없습니다.\n\n\n\n\n\n\nBackdoor Adjustment 예제\n\n◦ 데이터 설명\n   - 상황 : 미국인의 46%가 고혈압이 있고 고혈압은 사망률 증가와 연관되어 있습니다.\n   - 가설 : 이때 나트륨 섭취가 고혈압에 영향을 줄까요?\n   - Outcome : 혈압\n   - Treatment : 나트륨 섭취\n   - Covariates \\(W\\) : 나이,  Covariates \\(Z\\) : 소변에 배출되는 단백질 양\n     → 나이는 혈압과 신체의 나트륨 수치를 조절하는 Confounder이며, 소변에 배출되는 단백질 양이 많은 것은\n          고혈압과 나트륨 섭취량이 많기 때문입니다. 즉, \\(Z\\)는 Colider이며 \\(W\\)는 Cofounder 입니다.\n\n◦ Causal Graph\n   - 위에서 배운 Backdoor criterion에 의하면, Confounder인 \\(W\\)에 대한 Backdoor path만 막으면 됩니다. \n     Identification을 통해, 계산할 수 있는 Statistical estimand를 그래프 이용해 도출해 봅시다.\n   - Chapter 3에서 배운 방식으로 Statistical estimand를 작성해보면, \\(E_w,zE[Y|t,W]\\) 이지만,colider인 \\(z\\)는\n     막을 필요가 없어요. 그래서 Causal graph를 통해 도출된 Statistical estimand는 \\(E_wE[Y|t,W]\\)입니다.\n\n\n◦ Identification \n   - 위와 같은 방식을 통해, Backdoor path를 어떤 변수를 가지고 조절해야 하는지 쉽게 알 수 있습니다.\n   - 우리가 구해야하는 값(Causal estimand) : \\(E[Y|do(t)]\\)\n   - 우리가 구할 수 있는 값(Statistical estimand from causal graph) : \\(E_wE[Y|t,W]\\)\n   - 우리가 배운 과정을 적용해보면 최초의 종속변수는 ‘sodium’, ‘age’, ’proteinuria’과 같았겠죠?\n      이 때, Collider인 proteinuria (단백뇨)를 제거해서 ’sodium’과 ’age’를 종속변수로 활용해봅시다.\n\n◦ Estimation   - 데이터를 통해 ATE estimation을 확인하면, 각 Condition 마다 차이는 아래와 같습니다.\n   - 1) 변수 통제 하지 않았을 때 오류 : 407%\n     2) \\(T\\),\\(Y\\) 변수와 관계된 모든 영향을 통제했을 때 오류 : 19%\n     3) Backdoor path를 차단했을 때 오류 : 0.02%\n\n\n\n위 과정을 Python code를 활용해, 간단한 실험을 진행해볼게요.\n\n\n이전 예제에서의 변수간 영향력을 알 수 없으므로 위 그림과 같이 변수간의 관계를 숫자로 표현하였습니다.\nimport numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as sm\n\nnp.random.seed(12345)\nnum = 10000\n\nW = np.random.normal(size = num)\n\nT = 6 * W + np.random.normal(size = num)\nY = 5 * T +  3 * W + np.random.normal(size = num)\nZ = 2 * T + 7 * Y + np.random.normal(size = num)\n\ndata = pd.DataFrame({'T':T,'Y':Y,'Z':Z,'W':W})\n우리가 구하고자 하는 관계는 T가 Y에 미치는 인과관계를 구하고 이때 그림과 같이 5로 설정했습니다.\n먼저 어떠한 종속변수를 통제하지 않고 선형회귀모델을 사용하여 관계를 구해볼게요.\nmodel1 = sm.ols('Y ~ T', data).fit()\nmodel1.summary().tables[1]\n\nY에 대한 T의 영향이 5.4866으로 0.4866이라는 잡음이 생겼네요. 교란변수를 통제하지 않아서 오차가 생겼습니다.\n그러면 Y와 T사이 영향을 주는 모든 변수를 통제해볼까요?\nmodel2 = sm.ols('Y ~ T + W +Z', data).fit()\nmodel2.summary().tables[1]\n\nY에 대한 T의 영향이 -0.1770으로 우리가 구하고자 하는 5란 값과 매우 멀어졌습니다.\ncollider를 통제하면서 Y와 T간의 새로운 종속 관계를 만들어 내어 collider bias를 만들었군요.\n이처럼 모든 변수를 통제하여 collider 또한 통제하게 되면 편향이 발생할 위험이 있습니다.\n마지막으로 Y와 T사이 collider인 Z는 제거하지 말고 교란변수인 W만 통제해보겠습니다.\nmodel3 = sm.ols('Y ~ T + W', data).fit()\nmodel3.summary().tables[1]\n\nY에 대한 T의 영향이 4.9967으로 가장 5에 가까운 결과를 도출해냈습니다.\n변수간의 관계를 파악하여 non-causal association은 통제하고 정확한 causal association을 찾아내는 과정은 중요합니다.  \nTo be continued) 다음은 인과관계를 학습하는데 있어, Gold standard라고 불리는 Randomized Experiment에 대해 배울 예정입니다.\n\n\n\nReference \n\n◦ Lecture Notes : 2021 Summer Session on Causal Inference (박지용 교수님) [Link]\n◦ Blog\n   - Backdoor Adjustment [Link]\n   - 인과추론. 그래프와 확률 [Link]\n\n\n\n\n\nCitationBibTeX citation:@online{kim & hojae jeong2023,\n  author = {kim \\& hojae jeong, seongsoo},\n  title = {Chapter 4. {Causal} {Models}},\n  date = {2023-10-27},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n& hojae jeong, seongsoo kim. 2023. “Chapter 4. Causal\nModels.” October 27, 2023."
  }
]